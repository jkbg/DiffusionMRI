{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fitting.Fitter import create_fitter_from_configuration\n",
    "from models.model_creation import create_model_from_parameter_combination\n",
    "from utils.configuration_parser.gridsearch_configuration import get_gridsearch_configuration\n",
    "from utils.pickle_utils import save_gridsearch_result\n",
    "from utils.visualization_helpers import load_noisy_and_target_image, plot_image_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of GPUs:  1\n",
      "noisy_image_path: data/raw_images/diagonal_noisy.png  \n",
      "target_image_path: data/raw_images/diagonal_target.png  \n",
      "result_path: data/results/2020-11-09-13:42-gridsearch.pkl  \n",
      "image_shape: (256, 256, 3)  \n",
      "model_types: ['deep', 'conv']  \n",
      "input_shapes: [[12, 12], [10, 10], [8, 8], [6, 6], [4, 4], [2, 2]]  \n",
      "numbers_of_layers: [4, 6, 8]  \n",
      "numbers_of_hidden_channels: [32, 64, 128, 256]  \n",
      "number_of_runs: 5  \n",
      "number_of_iterations: 30000  \n",
      "learning_rate: 0.1  \n",
      "convergence_check_length: 100  \n",
      "log_frequency: 10  \n",
      "find_best: True  \n",
      "parameter_combinations: []  \n",
      "data_type: <class 'torch.cuda.FloatTensor'>  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "gridsearch_configuration = get_gridsearch_configuration()\n",
    "\n",
    "gridsearch_configuration.noisy_image_path = 'data/raw_images/diagonal_noisy.png'\n",
    "gridsearch_configuration.target_image_path = 'data/raw_images/diagonal_target.png'\n",
    "\n",
    "gridsearch_configuration.model_types = ['deep', 'conv']\n",
    "gridsearch_configuration.input_shapes = [[12, 12], [10,10], [8,8], [6,6], [4,4], [2,2]]\n",
    "gridsearch_configuration.numbers_of_hidden_channels = [32, 64, 128, 256]\n",
    "gridsearch_configuration.numbers_of_layers = [4, 6, 8]\n",
    "gridsearch_configuration.number_of_runs = 5\n",
    "\n",
    "gridsearch_configuration.log_frequency = 10\n",
    "print(gridsearch_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_combinations = gridsearch_configuration.generate_parameter_combinations()\n",
    "# for parameters in parameter_combinations:\n",
    "#     print(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images and Initialize Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noisy_image, target_image = load_noisy_and_target_image(gridsearch_configuration)\n",
    "fitter = create_fitter_from_configuration(gridsearch_configuration)\n",
    "\n",
    "plot = plot_image_grid([noisy_image, target_image], ['Noisy Image', 'Target Image'], nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++('deep', [12, 12], 4, 32)+++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00920, Loss: 0.001092, Target Loss: 0.008590, Minimum Loss at: 828 with 0.0010000\n",
      "Adam has converged at step 929.\n",
      "\n",
      "+++('deep', [12, 12], 4, 64)+++\n",
      "Step: 00440, Loss: 0.001112, Target Loss: 0.010263, Minimum Loss at: 347 with 0.0010550\n",
      "Adam has converged at step 449.\n",
      "\n",
      "+++('deep', [12, 12], 4, 128)+++\n",
      "Step: 00240, Loss: 0.009760, Target Loss: 0.000791, Minimum Loss at: 149 with 0.0030860\n",
      "Adam has converged at step 250.\n",
      "\n",
      "+++('deep', [12, 12], 4, 256)+++\n",
      "Step: 00630, Loss: 0.009974, Target Loss: 0.000457, Minimum Loss at: 533 with 0.0099340\n",
      "Adam has converged at step 634.\n",
      "\n",
      "+++('deep', [12, 12], 6, 32)+++\n",
      "Step: 00540, Loss: 0.000994, Target Loss: 0.009518, Minimum Loss at: 439 with 0.0009690\n",
      "Adam has converged at step 541.\n",
      "\n",
      "+++('deep', [12, 12], 6, 64)+++\n",
      "Step: 00690, Loss: 0.001294, Target Loss: 0.008669, Minimum Loss at: 590 with 0.0009590\n",
      "Adam has converged at step 691.\n",
      "\n",
      "+++('deep', [12, 12], 6, 128)+++\n",
      "Step: 00180, Loss: 0.009220, Target Loss: 0.001332, Minimum Loss at: 84 with 0.00788400\n",
      "Adam has converged at step 185.\n",
      "\n",
      "+++('deep', [12, 12], 6, 256)+++\n",
      "Step: 00310, Loss: 0.010970, Target Loss: 0.000730, Minimum Loss at: 214 with 0.0097880\n",
      "Adam has converged at step 315.\n",
      "\n",
      "+++('deep', [12, 12], 8, 32)+++\n",
      "Step: 00450, Loss: 0.001099, Target Loss: 0.008997, Minimum Loss at: 359 with 0.0009480\n",
      "Adam has converged at step 460.\n",
      "\n",
      "+++('deep', [12, 12], 8, 64)+++\n",
      "Step: 00460, Loss: 0.001080, Target Loss: 0.009237, Minimum Loss at: 361 with 0.0010360\n",
      "Adam has converged at step 462.\n",
      "\n",
      "+++('deep', [12, 12], 8, 128)+++\n",
      "Step: 00130, Loss: 0.010013, Target Loss: 0.000318, Minimum Loss at: 38 with 0.00856800\n",
      "Adam has converged at step 139.\n",
      "\n",
      "+++('deep', [12, 12], 8, 256)+++\n",
      "Step: 00350, Loss: 0.010816, Target Loss: 0.000528, Minimum Loss at: 235 with 0.0103170\n",
      "Adam has converged at step 360.\n",
      "\n",
      "+++('deep', [10, 10], 4, 32)+++\n",
      "Step: 00690, Loss: 0.001265, Target Loss: 0.009161, Minimum Loss at: 593 with 0.0010850\n",
      "Adam has converged at step 694.\n",
      "\n",
      "+++('deep', [10, 10], 4, 64)+++\n",
      "Step: 01030, Loss: 0.001247, Target Loss: 0.008912, Minimum Loss at: 880 with 0.0010940\n",
      "Adam has converged at step 1038.\n",
      "\n",
      "+++('deep', [10, 10], 4, 128)+++\n",
      "Step: 00280, Loss: 0.010000, Target Loss: 0.000441, Minimum Loss at: 184 with 0.0074820\n",
      "Adam has converged at step 285.\n",
      "\n",
      "+++('deep', [10, 10], 4, 256)+++\n",
      "Step: 00310, Loss: 0.010083, Target Loss: 0.000284, Minimum Loss at: 210 with 0.0100860\n",
      "Adam has converged at step 317.\n",
      "\n",
      "+++('deep', [10, 10], 6, 32)+++\n",
      "Step: 00580, Loss: 0.001286, Target Loss: 0.009332, Minimum Loss at: 489 with 0.0011500\n",
      "Adam has converged at step 590.\n",
      "\n",
      "+++('deep', [10, 10], 6, 64)+++\n",
      "Step: 00410, Loss: 0.001213, Target Loss: 0.009092, Minimum Loss at: 310 with 0.0011540\n",
      "Adam has converged at step 413.\n",
      "\n",
      "+++('deep', [10, 10], 6, 128)+++\n",
      "Step: 00280, Loss: 0.010004, Target Loss: 0.000542, Minimum Loss at: 189 with 0.0078110\n",
      "Adam has converged at step 290.\n",
      "\n",
      "+++('deep', [10, 10], 6, 256)+++\n",
      "Step: 00200, Loss: 0.010285, Target Loss: 0.000751, Minimum Loss at: 91 with 0.01017500\n",
      "Adam has converged at step 206.\n",
      "\n",
      "+++('deep', [10, 10], 8, 32)+++\n",
      "Step: 00420, Loss: 0.002002, Target Loss: 0.010295, Minimum Loss at: 317 with 0.0011330\n",
      "Adam has converged at step 425.\n",
      "\n",
      "+++('deep', [10, 10], 8, 64)+++\n",
      "Step: 00260, Loss: 0.001236, Target Loss: 0.009734, Minimum Loss at: 165 with 0.0011990\n",
      "Adam has converged at step 270.\n",
      "\n",
      "+++('deep', [10, 10], 8, 128)+++\n",
      "Step: 00270, Loss: 0.009747, Target Loss: 0.001148, Minimum Loss at: 177 with 0.0064110\n",
      "Adam has converged at step 278.\n",
      "\n",
      "+++('deep', [10, 10], 8, 256)+++\n",
      "Step: 00460, Loss: 0.010062, Target Loss: 0.000492, Minimum Loss at: 358 with 0.0099500\n",
      "Adam has converged at step 461.\n",
      "\n",
      "+++('deep', [8, 8], 4, 32)+++\n",
      "Step: 01040, Loss: 0.001314, Target Loss: 0.009494, Minimum Loss at: 941 with 0.0012380\n",
      "Adam has converged at step 1042.\n",
      "\n",
      "+++('deep', [8, 8], 4, 64)+++\n",
      "Step: 00340, Loss: 0.001743, Target Loss: 0.009775, Minimum Loss at: 248 with 0.0016130\n",
      "Adam has converged at step 349.\n",
      "\n",
      "+++('deep', [8, 8], 4, 128)+++\n",
      "Step: 00210, Loss: 0.010180, Target Loss: 0.001100, Minimum Loss at: 85 with 0.01016900\n",
      "Adam has converged at step 215.\n",
      "\n",
      "+++('deep', [8, 8], 4, 256)+++\n",
      "Step: 00620, Loss: 0.013573, Target Loss: 0.004471, Minimum Loss at: 521 with 0.0096410\n",
      "Adam has converged at step 622.\n",
      "\n",
      "+++('deep', [8, 8], 6, 32)+++\n",
      "Step: 00660, Loss: 0.001420, Target Loss: 0.008711, Minimum Loss at: 562 with 0.0013280\n",
      "Adam has converged at step 663.\n",
      "\n",
      "+++('deep', [8, 8], 6, 64)+++\n",
      "Step: 00600, Loss: 0.001138, Target Loss: 0.008768, Minimum Loss at: 506 with 0.0010720\n",
      "Adam has converged at step 608.\n",
      "\n",
      "+++('deep', [8, 8], 6, 128)+++\n",
      "Step: 00210, Loss: 0.009936, Target Loss: 0.000687, Minimum Loss at: 117 with 0.0051810\n",
      "Adam has converged at step 218.\n",
      "\n",
      "+++('deep', [8, 8], 6, 256)+++\n",
      "Step: 00510, Loss: 0.010355, Target Loss: 0.000772, Minimum Loss at: 410 with 0.0101770\n",
      "Adam has converged at step 513.\n",
      "\n",
      "+++('deep', [8, 8], 8, 32)+++\n",
      "Step: 00400, Loss: 0.001200, Target Loss: 0.008966, Minimum Loss at: 305 with 0.0010870\n",
      "Adam has converged at step 406.\n",
      "\n",
      "+++('deep', [8, 8], 8, 64)+++\n",
      "Step: 00190, Loss: 0.001338, Target Loss: 0.009015, Minimum Loss at: 91 with 0.00124800\n",
      "Adam has converged at step 192.\n",
      "\n",
      "+++('deep', [8, 8], 8, 128)+++\n",
      "Step: 00350, Loss: 0.010012, Target Loss: 0.000433, Minimum Loss at: 258 with 0.0091180\n",
      "Adam has converged at step 359.\n",
      "\n",
      "+++('deep', [8, 8], 8, 256)+++\n",
      "Step: 00200, Loss: 0.010399, Target Loss: 0.000314, Minimum Loss at: 109 with 0.0101790\n",
      "Adam has converged at step 210.\n",
      "\n",
      "+++('deep', [6, 6], 4, 32)+++\n",
      "Step: 00340, Loss: 0.003977, Target Loss: 0.009446, Minimum Loss at: 241 with 0.0017720\n",
      "Adam has converged at step 342.\n",
      "\n",
      "+++('deep', [6, 6], 4, 64)+++\n",
      "Step: 00250, Loss: 0.002137, Target Loss: 0.010896, Minimum Loss at: 156 with 0.0019710\n",
      "Adam has converged at step 257.\n",
      "\n",
      "+++('deep', [6, 6], 4, 128)+++\n",
      "Step: 00150, Loss: 0.010412, Target Loss: 0.001529, Minimum Loss at: 42 with 0.01015400\n",
      "Adam has converged at step 155.\n",
      "\n",
      "+++('deep', [6, 6], 4, 256)+++\n",
      "Step: 00210, Loss: 0.012272, Target Loss: 0.003007, Minimum Loss at: 116 with 0.0105890\n",
      "Adam has converged at step 217.\n",
      "\n",
      "+++('deep', [6, 6], 6, 32)+++\n",
      "Step: 00480, Loss: 0.001428, Target Loss: 0.009150, Minimum Loss at: 351 with 0.0011640\n",
      "Adam has converged at step 490.\n",
      "\n",
      "+++('deep', [6, 6], 6, 64)+++\n",
      "Step: 00430, Loss: 0.001236, Target Loss: 0.009285, Minimum Loss at: 337 with 0.0012220\n",
      "Adam has converged at step 438.\n",
      "\n",
      "+++('deep', [6, 6], 6, 128)+++\n",
      "Step: 00300, Loss: 0.009693, Target Loss: 0.001141, Minimum Loss at: 200 with 0.0078990\n",
      "Adam has converged at step 301.\n",
      "\n",
      "+++('deep', [6, 6], 6, 256)+++\n",
      "Step: 00280, Loss: 0.010570, Target Loss: 0.001220, Minimum Loss at: 144 with 0.0102310\n",
      "Adam has converged at step 282.\n",
      "\n",
      "+++('deep', [6, 6], 8, 32)+++\n",
      "Step: 00390, Loss: 0.001389, Target Loss: 0.009563, Minimum Loss at: 292 with 0.0011940\n",
      "Adam has converged at step 393.\n",
      "\n",
      "+++('deep', [6, 6], 8, 64)+++\n",
      "Step: 00740, Loss: 0.001666, Target Loss: 0.009470, Minimum Loss at: 647 with 0.0010690\n",
      "Adam has converged at step 748.\n",
      "\n",
      "+++('deep', [6, 6], 8, 128)+++\n",
      "Step: 00200, Loss: 0.010253, Target Loss: 0.000574, Minimum Loss at: 93 with 0.01009100\n",
      "Adam has converged at step 205.\n",
      "\n",
      "+++('deep', [6, 6], 8, 256)+++\n",
      "Step: 00220, Loss: 0.010528, Target Loss: 0.000618, Minimum Loss at: 76 with 0.01016000\n",
      "Adam has converged at step 225.\n",
      "\n",
      "+++('deep', [4, 4], 4, 32)+++\n",
      "Step: 00390, Loss: 0.006975, Target Loss: 0.017675, Minimum Loss at: 297 with 0.0053700\n",
      "Adam has converged at step 398.\n",
      "\n",
      "+++('deep', [4, 4], 4, 64)+++\n",
      "Step: 00700, Loss: 0.005510, Target Loss: 0.015061, Minimum Loss at: 606 with 0.0052670\n",
      "Adam has converged at step 707.\n",
      "\n",
      "+++('deep', [4, 4], 4, 128)+++\n",
      "Step: 00220, Loss: 0.013668, Target Loss: 0.007180, Minimum Loss at: 124 with 0.0135760\n",
      "Adam has converged at step 228.\n",
      "\n",
      "+++('deep', [4, 4], 4, 256)+++\n",
      "Step: 00110, Loss: 0.031649, Target Loss: 0.026093, Minimum Loss at: 17 with 0.01841600\n",
      "Adam has converged at step 118.\n",
      "\n",
      "+++('deep', [4, 4], 6, 32)+++\n",
      "Step: 00800, Loss: 0.001532, Target Loss: 0.010859, Minimum Loss at: 680 with 0.0013560\n",
      "Adam has converged at step 802.\n",
      "\n",
      "+++('deep', [4, 4], 6, 64)+++\n",
      "Step: 00260, Loss: 0.010929, Target Loss: 0.001932, Minimum Loss at: 167 with 0.0021780\n",
      "Adam has converged at step 268.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++('deep', [4, 4], 6, 128)+++\n",
      "Step: 00190, Loss: 0.010717, Target Loss: 0.002226, Minimum Loss at: 98 with 0.01027200\n",
      "Adam has converged at step 199.\n",
      "\n",
      "+++('deep', [4, 4], 6, 256)+++\n",
      "Step: 00400, Loss: 0.010546, Target Loss: 0.001447, Minimum Loss at: 300 with 0.0102100\n",
      "Adam has converged at step 401.\n",
      "\n",
      "+++('deep', [4, 4], 8, 32)+++\n",
      "Step: 00610, Loss: 0.001381, Target Loss: 0.009366, Minimum Loss at: 509 with 0.0012190\n",
      "Adam has converged at step 611.\n",
      "\n",
      "+++('deep', [4, 4], 8, 64)+++\n",
      "Step: 01050, Loss: 0.001300, Target Loss: 0.009172, Minimum Loss at: 952 with 0.0012520\n",
      "Adam has converged at step 1053.\n",
      "\n",
      "+++('deep', [4, 4], 8, 128)+++\n",
      "Step: 00290, Loss: 0.010624, Target Loss: 0.001671, Minimum Loss at: 197 with 0.0086180\n",
      "Adam has converged at step 298.\n",
      "\n",
      "+++('deep', [4, 4], 8, 256)+++\n",
      "Step: 00240, Loss: 0.013419, Target Loss: 0.003696, Minimum Loss at: 100 with 0.0111990\n",
      "Adam has converged at step 245.\n",
      "\n",
      "+++('deep', [2, 2], 4, 32)+++\n",
      "Step: 00380, Loss: 0.015466, Target Loss: 0.029249, Minimum Loss at: 289 with 0.0152720\n",
      "Adam has converged at step 390.\n",
      "\n",
      "+++('deep', [2, 2], 4, 64)+++\n",
      "Step: 00470, Loss: 0.018954, Target Loss: 0.037052, Minimum Loss at: 376 with 0.0154570\n",
      "Adam has converged at step 478.\n",
      "\n",
      "+++('deep', [2, 2], 4, 128)+++\n",
      "Step: 00160, Loss: 0.052652, Target Loss: 0.058665, Minimum Loss at: 67 with 0.03252300\n",
      "Adam has converged at step 168.\n",
      "\n",
      "+++('deep', [2, 2], 4, 256)+++\n",
      "Step: 00160, Loss: 0.058423, Target Loss: 0.062774, Minimum Loss at: 60 with 0.04026300\n",
      "Adam has converged at step 161.\n",
      "\n",
      "+++('deep', [2, 2], 6, 32)+++\n",
      "Step: 00760, Loss: 0.002009, Target Loss: 0.009934, Minimum Loss at: 660 with 0.0017380\n",
      "Adam has converged at step 761.\n",
      "\n",
      "+++('deep', [2, 2], 6, 64)+++\n",
      "Step: 00470, Loss: 0.003157, Target Loss: 0.011819, Minimum Loss at: 373 with 0.0025350\n",
      "Adam has converged at step 474.\n",
      "\n",
      "+++('deep', [2, 2], 6, 128)+++\n",
      "Step: 00430, Loss: 0.011238, Target Loss: 0.003077, Minimum Loss at: 332 with 0.0086260\n",
      "Adam has converged at step 433.\n",
      "\n",
      "+++('deep', [2, 2], 6, 256)+++\n",
      "Step: 00450, Loss: 0.011210, Target Loss: 0.002273, Minimum Loss at: 355 with 0.0103970\n",
      "Adam has converged at step 456.\n",
      "\n",
      "+++('deep', [2, 2], 8, 32)+++\n",
      "Step: 00350, Loss: 0.002207, Target Loss: 0.010816, Minimum Loss at: 251 with 0.0017730\n",
      "Adam has converged at step 352.\n",
      "\n",
      "+++('deep', [2, 2], 8, 64)+++\n",
      "Step: 00340, Loss: 0.004582, Target Loss: 0.014827, Minimum Loss at: 241 with 0.0022580\n",
      "Adam has converged at step 342.\n",
      "\n",
      "+++('deep', [2, 2], 8, 128)+++\n",
      "Step: 00500, Loss: 0.010367, Target Loss: 0.001990, Minimum Loss at: 403 with 0.0090750\n",
      "Adam has converged at step 504.\n",
      "\n",
      "+++('deep', [2, 2], 8, 256)+++\n",
      "Step: 00220, Loss: 0.027200, Target Loss: 0.023503, Minimum Loss at: 120 with 0.0119120\n",
      "Adam has converged at step 221.\n",
      "\n",
      "+++('conv', [12, 12], 4, 32)+++\n",
      "Step: 00610, Loss: 0.021478, Target Loss: 0.040661, Minimum Loss at: 511 with 0.0209860\n",
      "Adam has converged at step 612.\n",
      "\n",
      "+++('conv', [12, 12], 4, 64)+++\n",
      "Step: 00900, Loss: 0.007777, Target Loss: 0.019785, Minimum Loss at: 804 with 0.0061300\n",
      "Adam has converged at step 905.\n",
      "\n",
      "+++('conv', [12, 12], 4, 128)+++\n",
      "Step: 01110, Loss: 0.004187, Target Loss: 0.014494, Minimum Loss at: 1018 with 0.002814\n",
      "Adam has converged at step 1119.\n",
      "\n",
      "+++('conv', [12, 12], 4, 256)+++\n",
      "Step: 00780, Loss: 0.017846, Target Loss: 0.034602, Minimum Loss at: 686 with 0.0118090\n",
      "Adam has converged at step 788.\n",
      "\n",
      "+++('conv', [12, 12], 6, 32)+++\n",
      "Step: 00880, Loss: 0.004095, Target Loss: 0.013239, Minimum Loss at: 788 with 0.0023530\n",
      "Adam has converged at step 889.\n",
      "\n",
      "+++('conv', [12, 12], 6, 64)+++\n",
      "Step: 00470, Loss: 0.037724, Target Loss: 0.059886, Minimum Loss at: 375 with 0.0171590\n",
      "Adam has converged at step 476.\n",
      "\n",
      "+++('conv', [12, 12], 6, 128)+++\n",
      "Step: 00830, Loss: 0.013637, Target Loss: 0.027031, Minimum Loss at: 738 with 0.0017860\n",
      "Adam has converged at step 839.\n",
      "\n",
      "+++('conv', [12, 12], 6, 256)+++\n",
      "Step: 00510, Loss: 0.022607, Target Loss: 0.040101, Minimum Loss at: 410 with 0.0206650\n",
      "Adam has converged at step 511.\n",
      "\n",
      "+++('conv', [12, 12], 8, 32)+++\n",
      "Step: 00370, Loss: 0.041545, Target Loss: 0.065910, Minimum Loss at: 271 with 0.0157950\n",
      "Adam has converged at step 372.\n",
      "\n",
      "+++('conv', [12, 12], 8, 64)+++\n",
      "Step: 00500, Loss: 0.015096, Target Loss: 0.030039, Minimum Loss at: 405 with 0.0130490\n",
      "Adam has converged at step 506.\n",
      "\n",
      "+++('conv', [12, 12], 8, 128)+++\n",
      "Step: 00270, Loss: 0.086998, Target Loss: 0.125686, Minimum Loss at: 171 with 0.0571560\n",
      "Adam has converged at step 272.\n",
      "\n",
      "+++('conv', [12, 12], 8, 256)+++\n",
      "Step: 00320, Loss: 0.054609, Target Loss: 0.081001, Minimum Loss at: 227 with 0.0463760\n",
      "Adam has converged at step 328.\n",
      "\n",
      "+++('conv', [10, 10], 4, 32)+++\n",
      "Step: 00830, Loss: 0.003797, Target Loss: 0.015457, Minimum Loss at: 737 with 0.0031740\n",
      "Adam has converged at step 838.\n",
      "\n",
      "+++('conv', [10, 10], 4, 64)+++\n",
      "Step: 00960, Loss: 0.006971, Target Loss: 0.019460, Minimum Loss at: 869 with 0.0029930\n",
      "Adam has converged at step 970.\n",
      "\n",
      "+++('conv', [10, 10], 4, 128)+++\n",
      "Step: 01260, Loss: 0.007103, Target Loss: 0.019775, Minimum Loss at: 1162 with 0.005005\n",
      "Adam has converged at step 1263.\n",
      "\n",
      "+++('conv', [10, 10], 4, 256)+++\n",
      "Step: 01320, Loss: 0.003451, Target Loss: 0.013940, Minimum Loss at: 1220 with 0.003298\n",
      "Adam has converged at step 1321.\n",
      "\n",
      "+++('conv', [10, 10], 6, 32)+++\n",
      "Step: 00570, Loss: 0.008226, Target Loss: 0.022696, Minimum Loss at: 470 with 0.0069700\n",
      "Adam has converged at step 571.\n",
      "\n",
      "+++('conv', [10, 10], 6, 64)+++\n",
      "Step: 00400, Loss: 0.023558, Target Loss: 0.041169, Minimum Loss at: 306 with 0.0159170\n",
      "Adam has converged at step 407.\n",
      "\n",
      "+++('conv', [10, 10], 6, 128)+++\n",
      "Step: 01010, Loss: 0.001337, Target Loss: 0.011571, Minimum Loss at: 914 with 0.0008600\n",
      "Adam has converged at step 1015.\n",
      "\n",
      "+++('conv', [10, 10], 6, 256)+++\n",
      "Step: 00650, Loss: 0.012681, Target Loss: 0.026298, Minimum Loss at: 550 with 0.0049220\n",
      "Adam has converged at step 652.\n",
      "\n",
      "+++('conv', [10, 10], 8, 32)+++\n",
      "Step: 00510, Loss: 0.015863, Target Loss: 0.030787, Minimum Loss at: 416 with 0.0116900\n",
      "Adam has converged at step 518.\n",
      "\n",
      "+++('conv', [10, 10], 8, 64)+++\n",
      "Step: 00270, Loss: 0.042267, Target Loss: 0.067538, Minimum Loss at: 170 with 0.0285350\n",
      "Adam has converged at step 271.\n",
      "\n",
      "+++('conv', [10, 10], 8, 128)+++\n",
      "Step: 00700, Loss: 0.011111, Target Loss: 0.024759, Minimum Loss at: 608 with 0.0051980\n",
      "Adam has converged at step 709.\n",
      "\n",
      "+++('conv', [10, 10], 8, 256)+++\n",
      "Step: 00720, Loss: 0.539248, Target Loss: 0.566408, Minimum Loss at: 621 with 0.0035420\n",
      "Adam has converged at step 723.\n",
      "\n",
      "+++('conv', [8, 8], 4, 32)+++\n",
      "Step: 00930, Loss: 0.009819, Target Loss: 0.022640, Minimum Loss at: 830 with 0.0074720\n",
      "Adam has converged at step 931.\n",
      "\n",
      "+++('conv', [8, 8], 4, 64)+++\n",
      "Step: 01140, Loss: 0.005865, Target Loss: 0.020778, Minimum Loss at: 1037 with 0.005286\n",
      "Adam has converged at step 1141.\n",
      "\n",
      "+++('conv', [8, 8], 4, 128)+++\n",
      "Step: 01030, Loss: 0.003646, Target Loss: 0.014731, Minimum Loss at: 938 with 0.0028980\n",
      "Adam has converged at step 1040.\n",
      "\n",
      "+++('conv', [8, 8], 4, 256)+++\n",
      "Step: 01280, Loss: 0.006979, Target Loss: 0.018252, Minimum Loss at: 1185 with 0.004924\n",
      "Adam has converged at step 1286.\n",
      "\n",
      "+++('conv', [8, 8], 6, 32)+++\n",
      "Step: 01640, Loss: 0.000168, Target Loss: 0.008806, Minimum Loss at: 1548 with 0.000106\n",
      "Adam has converged at step 1650.\n",
      "\n",
      "+++('conv', [8, 8], 6, 64)+++\n",
      "Step: 00520, Loss: 0.000951, Target Loss: 0.010847, Minimum Loss at: 421 with 0.0004350\n",
      "Adam has converged at step 522.\n",
      "\n",
      "+++('conv', [8, 8], 6, 128)+++\n",
      "Step: 02070, Loss: 0.000825, Target Loss: 0.010500, Minimum Loss at: 1976 with 0.000173\n",
      "Adam has converged at step 2077.\n",
      "\n",
      "+++('conv', [8, 8], 6, 256)+++\n",
      "Step: 01230, Loss: 0.000608, Target Loss: 0.010997, Minimum Loss at: 1130 with 0.000474\n",
      "Adam has converged at step 1231.\n",
      "\n",
      "+++('conv', [8, 8], 8, 32)+++\n",
      "Step: 00410, Loss: 0.036181, Target Loss: 0.058817, Minimum Loss at: 313 with 0.0074310\n",
      "Adam has converged at step 414.\n",
      "\n",
      "+++('conv', [8, 8], 8, 64)+++\n",
      "Step: 01230, Loss: 0.001138, Target Loss: 0.011425, Minimum Loss at: 1130 with 0.000754\n",
      "Adam has converged at step 1232.\n",
      "\n",
      "+++('conv', [8, 8], 8, 128)+++\n",
      "Step: 00530, Loss: 0.011439, Target Loss: 0.025269, Minimum Loss at: 433 with 0.0095890\n",
      "Adam has converged at step 534.\n",
      "\n",
      "+++('conv', [8, 8], 8, 256)+++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00530, Loss: 0.013789, Target Loss: 0.028188, Minimum Loss at: 430 with 0.0134130\n",
      "Adam has converged at step 531.\n",
      "\n",
      "+++('conv', [6, 6], 4, 32)+++\n",
      "Step: 00670, Loss: 0.024110, Target Loss: 0.038355, Minimum Loss at: 574 with 0.0190510\n",
      "Adam has converged at step 675.\n",
      "\n",
      "+++('conv', [6, 6], 4, 64)+++\n",
      "Step: 01000, Loss: 0.017590, Target Loss: 0.035384, Minimum Loss at: 901 with 0.0129430\n",
      "Adam has converged at step 1002.\n",
      "\n",
      "+++('conv', [6, 6], 4, 128)+++\n",
      "Step: 00990, Loss: 0.008921, Target Loss: 0.022612, Minimum Loss at: 892 with 0.0056970\n",
      "Adam has converged at step 993.\n",
      "\n",
      "+++('conv', [6, 6], 4, 256)+++\n",
      "Step: 00960, Loss: 0.013462, Target Loss: 0.028086, Minimum Loss at: 863 with 0.0124880\n",
      "Adam has converged at step 964.\n",
      "\n",
      "+++('conv', [6, 6], 6, 32)+++\n",
      "Step: 00720, Loss: 0.002485, Target Loss: 0.013316, Minimum Loss at: 621 with 0.0013770\n",
      "Adam has converged at step 722.\n",
      "\n",
      "+++('conv', [6, 6], 6, 64)+++\n",
      "Step: 00580, Loss: 0.009006, Target Loss: 0.021996, Minimum Loss at: 485 with 0.0012290\n",
      "Adam has converged at step 587.\n",
      "\n",
      "+++('conv', [6, 6], 6, 128)+++\n",
      "Step: 00490, Loss: 0.003310, Target Loss: 0.014289, Minimum Loss at: 394 with 0.0030020\n",
      "Adam has converged at step 496.\n",
      "\n",
      "+++('conv', [6, 6], 6, 256)+++\n",
      "Step: 00660, Loss: 0.004304, Target Loss: 0.016707, Minimum Loss at: 563 with 0.0031920\n",
      "Adam has converged at step 664.\n",
      "\n",
      "+++('conv', [6, 6], 8, 32)+++\n",
      "Step: 00330, Loss: 0.022545, Target Loss: 0.040537, Minimum Loss at: 232 with 0.0110930\n",
      "Adam has converged at step 334.\n",
      "\n",
      "+++('conv', [6, 6], 8, 64)+++\n",
      "Step: 00320, Loss: 0.008402, Target Loss: 0.020627, Minimum Loss at: 222 with 0.0067000\n",
      "Adam has converged at step 323.\n",
      "\n",
      "+++('conv', [6, 6], 8, 128)+++\n",
      "Step: 00420, Loss: 0.006679, Target Loss: 0.018561, Minimum Loss at: 325 with 0.0055770\n",
      "Adam has converged at step 426.\n",
      "\n",
      "+++('conv', [6, 6], 8, 256)+++\n",
      "Step: 00400, Loss: 0.008979, Target Loss: 0.021396, Minimum Loss at: 304 with 0.0047310\n",
      "Adam has converged at step 405.\n",
      "\n",
      "+++('conv', [4, 4], 4, 32)+++\n",
      "Step: 01050, Loss: 0.009557, Target Loss: 0.022653, Minimum Loss at: 950 with 0.0055020\n",
      "Adam has converged at step 1052.\n",
      "\n",
      "+++('conv', [4, 4], 4, 64)+++\n",
      "Step: 00940, Loss: 0.011959, Target Loss: 0.025669, Minimum Loss at: 844 with 0.0080940\n",
      "Adam has converged at step 945.\n",
      "\n",
      "+++('conv', [4, 4], 4, 128)+++\n",
      "Step: 00730, Loss: 0.018063, Target Loss: 0.035200, Minimum Loss at: 638 with 0.0115900\n",
      "Adam has converged at step 739.\n",
      "\n",
      "+++('conv', [4, 4], 4, 256)+++\n",
      "Step: 01080, Loss: 0.010706, Target Loss: 0.027371, Minimum Loss at: 987 with 0.0077200\n",
      "Adam has converged at step 1088.\n",
      "\n",
      "+++('conv', [4, 4], 6, 32)+++\n",
      "Step: 00360, Loss: 0.007720, Target Loss: 0.018598, Minimum Loss at: 263 with 0.0024180\n",
      "Adam has converged at step 364.\n",
      "\n",
      "+++('conv', [4, 4], 6, 64)+++\n",
      "Step: 00550, Loss: 0.002828, Target Loss: 0.013498, Minimum Loss at: 455 with 0.0015620\n",
      "Adam has converged at step 556.\n",
      "\n",
      "+++('conv', [4, 4], 6, 128)+++\n",
      "Step: 00500, Loss: 0.074177, Target Loss: 0.103039, Minimum Loss at: 400 with 0.0025780\n",
      "Adam has converged at step 501.\n",
      "\n",
      "+++('conv', [4, 4], 6, 256)+++\n",
      "Step: 00560, Loss: 0.003221, Target Loss: 0.013480, Minimum Loss at: 465 with 0.0021980\n",
      "Adam has converged at step 567.\n",
      "\n",
      "+++('conv', [4, 4], 8, 32)+++\n",
      "Step: 00280, Loss: 0.013667, Target Loss: 0.028022, Minimum Loss at: 182 with 0.0044410\n",
      "Adam has converged at step 283.\n",
      "\n",
      "+++('conv', [4, 4], 8, 64)+++\n",
      "Step: 00570, Loss: 0.002902, Target Loss: 0.013823, Minimum Loss at: 469 with 0.0024960\n",
      "Adam has converged at step 571.\n",
      "\n",
      "+++('conv', [4, 4], 8, 128)+++\n",
      "Step: 00250, Loss: 0.018447, Target Loss: 0.033579, Minimum Loss at: 155 with 0.0071480\n",
      "Adam has converged at step 256.\n",
      "\n",
      "+++('conv', [4, 4], 8, 256)+++\n",
      "Step: 00310, Loss: 0.024175, Target Loss: 0.044899, Minimum Loss at: 217 with 0.0171450\n",
      "Adam has converged at step 319.\n",
      "\n",
      "+++('conv', [2, 2], 4, 32)+++\n",
      "Step: 00490, Loss: 0.029769, Target Loss: 0.049900, Minimum Loss at: 393 with 0.0286170\n",
      "Adam has converged at step 499.\n",
      "\n",
      "+++('conv', [2, 2], 4, 64)+++\n",
      "Step: 00620, Loss: 0.028710, Target Loss: 0.048751, Minimum Loss at: 486 with 0.0285230\n",
      "Adam has converged at step 626.\n",
      "\n",
      "+++('conv', [2, 2], 4, 128)+++\n",
      "Step: 00350, Loss: 0.061579, Target Loss: 0.091810, Minimum Loss at: 252 with 0.0587880\n",
      "Adam has converged at step 353.\n",
      "\n",
      "+++('conv', [2, 2], 4, 256)+++\n",
      "Step: 00680, Loss: 0.032238, Target Loss: 0.052084, Minimum Loss at: 581 with 0.0310700\n",
      "Adam has converged at step 682.\n",
      "\n",
      "+++('conv', [2, 2], 6, 32)+++\n",
      "Step: 00390, Loss: 0.006075, Target Loss: 0.017224, Minimum Loss at: 291 with 0.0018200\n",
      "Adam has converged at step 392.\n",
      "\n",
      "+++('conv', [2, 2], 6, 64)+++\n",
      "Step: 00500, Loss: 0.001808, Target Loss: 0.012422, Minimum Loss at: 400 with 0.0015990\n",
      "Adam has converged at step 501.\n",
      "\n",
      "+++('conv', [2, 2], 6, 128)+++\n",
      "Step: 00340, Loss: 0.004903, Target Loss: 0.016118, Minimum Loss at: 247 with 0.0031310\n",
      "Adam has converged at step 348.\n",
      "\n",
      "+++('conv', [2, 2], 6, 256)+++\n",
      "Step: 00670, Loss: 0.004640, Target Loss: 0.016564, Minimum Loss at: 574 with 0.0045290\n",
      "Adam has converged at step 675.\n",
      "\n",
      "+++('conv', [2, 2], 8, 32)+++\n",
      "Step: 00880, Loss: 0.000210, Target Loss: 0.009796, Minimum Loss at: 788 with 0.0001630\n",
      "Adam has converged at step 889.\n",
      "\n",
      "+++('conv', [2, 2], 8, 64)+++\n",
      "Step: 00690, Loss: 0.000412, Target Loss: 0.010834, Minimum Loss at: 591 with 0.0003620\n",
      "Adam has converged at step 692.\n",
      "\n",
      "+++('conv', [2, 2], 8, 128)+++\n",
      "Step: 01840, Loss: 0.000144, Target Loss: 0.010115, Minimum Loss at: 1744 with 0.000139\n",
      "Adam has converged at step 1845.\n",
      "\n",
      "+++('conv', [2, 2], 8, 256)+++\n",
      "Step: 01140, Loss: 0.000338, Target Loss: 0.009923, Minimum Loss at: 1041 with 0.000315\n",
      "Adam has converged at step 1143.\n",
      "\n",
      "+++('deep', [12, 12], 4, 32)+++\n",
      "Step: 00490, Loss: 0.001581, Target Loss: 0.006586, Minimum Loss at: 398 with 0.0012440\n",
      "Adam has converged at step 499.\n",
      "\n",
      "+++('deep', [12, 12], 4, 64)+++\n",
      "Step: 00580, Loss: 0.010315, Target Loss: 0.000853, Minimum Loss at: 484 with 0.0011140\n",
      "Adam has converged at step 587.\n",
      "\n",
      "+++('deep', [12, 12], 4, 128)+++\n",
      "Step: 00170, Loss: 0.008125, Target Loss: 0.003071, Minimum Loss at: 73 with 0.00417400\n",
      "Adam has converged at step 174.\n",
      "\n",
      "+++('deep', [12, 12], 4, 256)+++\n",
      "Step: 00300, Loss: 0.010129, Target Loss: 0.000244, Minimum Loss at: 204 with 0.0101130\n",
      "Adam has converged at step 309.\n",
      "\n",
      "+++('deep', [12, 12], 6, 32)+++\n",
      "Step: 00660, Loss: 0.001090, Target Loss: 0.009166, Minimum Loss at: 569 with 0.0010350\n",
      "Adam has converged at step 670.\n",
      "\n",
      "+++('deep', [12, 12], 6, 64)+++\n",
      "Step: 00600, Loss: 0.001013, Target Loss: 0.008724, Minimum Loss at: 502 with 0.0009470\n",
      "Adam has converged at step 603.\n",
      "\n",
      "+++('deep', [12, 12], 6, 128)+++\n",
      "Step: 00290, Loss: 0.009897, Target Loss: 0.000581, Minimum Loss at: 191 with 0.0096130\n",
      "Adam has converged at step 292.\n",
      "\n",
      "+++('deep', [12, 12], 6, 256)+++\n",
      "Step: 00290, Loss: 0.010261, Target Loss: 0.000730, Minimum Loss at: 173 with 0.0101470\n",
      "Adam has converged at step 293.\n",
      "\n",
      "+++('deep', [12, 12], 8, 32)+++\n",
      "Step: 00400, Loss: 0.001088, Target Loss: 0.009341, Minimum Loss at: 302 with 0.0010640\n",
      "Adam has converged at step 403.\n",
      "\n",
      "+++('deep', [12, 12], 8, 64)+++\n",
      "Step: 00310, Loss: 0.001199, Target Loss: 0.008864, Minimum Loss at: 218 with 0.0009740\n",
      "Adam has converged at step 319.\n",
      "\n",
      "+++('deep', [12, 12], 8, 128)+++\n",
      "Step: 00600, Loss: 0.001225, Target Loss: 0.007791, Minimum Loss at: 499 with 0.0010870\n",
      "Adam has converged at step 604.\n",
      "\n",
      "+++('deep', [12, 12], 8, 256)+++\n",
      "Step: 00590, Loss: 0.010603, Target Loss: 0.000592, Minimum Loss at: 486 with 0.0100890\n",
      "Adam has converged at step 593.\n",
      "\n",
      "+++('deep', [10, 10], 4, 32)+++\n",
      "Step: 00790, Loss: 0.001490, Target Loss: 0.008844, Minimum Loss at: 690 with 0.0012600\n",
      "Adam has converged at step 792.\n",
      "\n",
      "+++('deep', [10, 10], 4, 64)+++\n",
      "Step: 00330, Loss: 0.001378, Target Loss: 0.007332, Minimum Loss at: 238 with 0.0012440\n",
      "Adam has converged at step 339.\n",
      "\n",
      "+++('deep', [10, 10], 4, 128)+++\n",
      "Step: 00220, Loss: 0.009922, Target Loss: 0.000633, Minimum Loss at: 123 with 0.0079790\n",
      "Adam has converged at step 224.\n",
      "\n",
      "+++('deep', [10, 10], 4, 256)+++\n",
      "Step: 00200, Loss: 0.010630, Target Loss: 0.000703, Minimum Loss at: 109 with 0.0101790\n",
      "Adam has converged at step 210.\n",
      "\n",
      "+++('deep', [10, 10], 6, 32)+++\n",
      "Step: 00370, Loss: 0.001205, Target Loss: 0.009365, Minimum Loss at: 278 with 0.0011210\n",
      "Adam has converged at step 379.\n",
      "\n",
      "+++('deep', [10, 10], 6, 64)+++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00160, Loss: 0.009419, Target Loss: 0.001225, Minimum Loss at: 62 with 0.00227300\n",
      "Adam has converged at step 166.\n",
      "\n",
      "+++('deep', [10, 10], 6, 128)+++\n",
      "Step: 00310, Loss: 0.009856, Target Loss: 0.000586, Minimum Loss at: 95 with 0.00978200\n",
      "Adam has converged at step 312.\n",
      "\n",
      "+++('deep', [10, 10], 6, 256)+++\n",
      "Step: 00310, Loss: 0.011782, Target Loss: 0.001684, Minimum Loss at: 215 with 0.0102710\n",
      "Adam has converged at step 318.\n",
      "\n",
      "+++('deep', [10, 10], 8, 32)+++\n",
      "Step: 00490, Loss: 0.001286, Target Loss: 0.008489, Minimum Loss at: 391 with 0.0011680\n",
      "Adam has converged at step 492.\n",
      "\n",
      "+++('deep', [10, 10], 8, 64)+++\n",
      "Step: 00530, Loss: 0.001270, Target Loss: 0.007251, Minimum Loss at: 433 with 0.0011040\n",
      "Adam has converged at step 535.\n",
      "\n",
      "+++('deep', [10, 10], 8, 128)+++\n",
      "Step: 00270, Loss: 0.009915, Target Loss: 0.000439, Minimum Loss at: 169 with 0.0096640\n",
      "Adam has converged at step 271.\n",
      "\n",
      "+++('deep', [10, 10], 8, 256)+++\n",
      "Step: 00420, Loss: 0.010332, Target Loss: 0.000704, Minimum Loss at: 327 with 0.0101920\n",
      "Adam has converged at step 428.\n",
      "\n",
      "+++('deep', [8, 8], 4, 32)+++\n",
      "Step: 00710, Loss: 0.001574, Target Loss: 0.010649, Minimum Loss at: 618 with 0.0013910\n",
      "Adam has converged at step 719.\n",
      "\n",
      "+++('deep', [8, 8], 4, 64)+++\n",
      "Step: 00360, Loss: 0.009658, Target Loss: 0.001613, Minimum Loss at: 264 with 0.0014050\n",
      "Adam has converged at step 365.\n",
      "\n",
      "+++('deep', [8, 8], 4, 128)+++\n",
      "Step: 00220, Loss: 0.010127, Target Loss: 0.000791, Minimum Loss at: 126 with 0.0031950\n",
      "Adam has converged at step 227.\n",
      "\n",
      "+++('deep', [8, 8], 4, 256)+++\n",
      "Step: 00440, Loss: 0.010410, Target Loss: 0.000656, Minimum Loss at: 209 with 0.0101320\n",
      "Adam has converged at step 448.\n",
      "\n",
      "+++('deep', [8, 8], 6, 32)+++\n",
      "Step: 01220, Loss: 0.001091, Target Loss: 0.009588, Minimum Loss at: 1129 with 0.000892\n",
      "Adam has converged at step 1230.\n",
      "\n",
      "+++('deep', [8, 8], 6, 64)+++\n",
      "Step: 00340, Loss: 0.009242, Target Loss: 0.001637, Minimum Loss at: 243 with 0.0015370\n",
      "Adam has converged at step 345.\n",
      "\n",
      "+++('deep', [8, 8], 6, 128)+++\n",
      "Step: 00180, Loss: 0.010115, Target Loss: 0.000192, Minimum Loss at: 84 with 0.00632600\n",
      "Adam has converged at step 185.\n",
      "\n",
      "+++('deep', [8, 8], 6, 256)+++\n",
      "Step: 00260, Loss: 0.010372, Target Loss: 0.000331, Minimum Loss at: 143 with 0.0101840\n",
      "Adam has converged at step 264.\n",
      "\n",
      "+++('deep', [8, 8], 8, 32)+++\n",
      "Step: 00760, Loss: 0.001155, Target Loss: 0.009127, Minimum Loss at: 666 with 0.0010800\n",
      "Adam has converged at step 768.\n",
      "\n",
      "+++('deep', [8, 8], 8, 64)+++\n",
      "Step: 00210, Loss: 0.001912, Target Loss: 0.008794, Minimum Loss at: 110 with 0.0013610\n",
      "Adam has converged at step 211.\n",
      "\n",
      "+++('deep', [8, 8], 8, 128)+++\n",
      "Step: 00450, Loss: 0.010218, Target Loss: 0.000257, Minimum Loss at: 352 with 0.0074980\n",
      "Adam has converged at step 453.\n",
      "\n",
      "+++('deep', [8, 8], 8, 256)+++\n",
      "Step: 00180, Loss: 0.010417, Target Loss: 0.000224, Minimum Loss at: 82 with 0.01020500\n",
      "Adam has converged at step 183.\n",
      "\n",
      "+++('deep', [6, 6], 4, 32)+++\n",
      "Step: 00420, Loss: 0.001747, Target Loss: 0.009857, Minimum Loss at: 320 with 0.0016560\n",
      "Adam has converged at step 422.\n",
      "\n",
      "+++('deep', [6, 6], 4, 64)+++\n",
      "Step: 00280, Loss: 0.001920, Target Loss: 0.009098, Minimum Loss at: 187 with 0.0018820\n",
      "Adam has converged at step 290.\n",
      "\n",
      "+++('deep', [6, 6], 4, 128)+++\n",
      "Step: 00190, Loss: 0.010666, Target Loss: 0.001890, Minimum Loss at: 96 with 0.01031000\n",
      "Adam has converged at step 197.\n",
      "\n",
      "+++('deep', [6, 6], 4, 256)+++\n",
      "Step: 00470, Loss: 0.010596, Target Loss: 0.001555, Minimum Loss at: 353 with 0.0103620\n",
      "Adam has converged at step 480.\n",
      "\n",
      "+++('deep', [6, 6], 6, 32)+++\n",
      "Step: 00750, Loss: 0.001433, Target Loss: 0.009527, Minimum Loss at: 655 with 0.0011450\n",
      "Adam has converged at step 756.\n",
      "\n",
      "+++('deep', [6, 6], 6, 64)+++\n",
      "Step: 00200, Loss: 0.010700, Target Loss: 0.001891, Minimum Loss at: 101 with 0.0016410\n",
      "Adam has converged at step 203.\n",
      "\n",
      "+++('deep', [6, 6], 6, 128)+++\n",
      "Step: 00160, Loss: 0.010084, Target Loss: 0.000648, Minimum Loss at: 67 with 0.00572500\n",
      "Adam has converged at step 168.\n",
      "\n",
      "+++('deep', [6, 6], 6, 256)+++\n",
      "Step: 00200, Loss: 0.010380, Target Loss: 0.000965, Minimum Loss at: 99 with 0.01019000\n",
      "Adam has converged at step 210.\n",
      "\n",
      "+++('deep', [6, 6], 8, 32)+++\n",
      "Step: 00400, Loss: 0.001337, Target Loss: 0.009722, Minimum Loss at: 302 with 0.0012440\n",
      "Adam has converged at step 404.\n",
      "\n",
      "+++('deep', [6, 6], 8, 64)+++\n",
      "Step: 00370, Loss: 0.001396, Target Loss: 0.009568, Minimum Loss at: 273 with 0.0013010\n",
      "Adam has converged at step 377.\n",
      "\n",
      "+++('deep', [6, 6], 8, 128)+++\n",
      "Step: 00120, Loss: 0.009847, Target Loss: 0.000688, Minimum Loss at: 27 with 0.00894100\n",
      "Adam has converged at step 128.\n",
      "\n",
      "+++('deep', [6, 6], 8, 256)+++\n",
      "Step: 00350, Loss: 0.010663, Target Loss: 0.000512, Minimum Loss at: 251 with 0.0106300\n",
      "Adam has converged at step 352.\n",
      "\n",
      "+++('deep', [4, 4], 4, 32)+++\n",
      "Step: 00340, Loss: 0.005920, Target Loss: 0.015794, Minimum Loss at: 242 with 0.0053730\n",
      "Adam has converged at step 343.\n",
      "\n",
      "+++('deep', [4, 4], 4, 64)+++\n",
      "Step: 00380, Loss: 0.006075, Target Loss: 0.016346, Minimum Loss at: 278 with 0.0052960\n",
      "Adam has converged at step 381.\n",
      "\n",
      "+++('deep', [4, 4], 4, 128)+++\n",
      "Step: 00810, Loss: 0.006621, Target Loss: 0.017412, Minimum Loss at: 719 with 0.0052270\n",
      "Adam has converged at step 820.\n",
      "\n",
      "+++('deep', [4, 4], 4, 256)+++\n",
      "Step: 00170, Loss: 0.029726, Target Loss: 0.024241, Minimum Loss at: 78 with 0.01991100\n",
      "Adam has converged at step 179.\n",
      "\n",
      "+++('deep', [4, 4], 6, 32)+++\n",
      "Step: 00390, Loss: 0.001610, Target Loss: 0.009336, Minimum Loss at: 295 with 0.0014960\n",
      "Adam has converged at step 396.\n",
      "\n",
      "+++('deep', [4, 4], 6, 64)+++\n",
      "Step: 00330, Loss: 0.001903, Target Loss: 0.010026, Minimum Loss at: 222 with 0.0016980\n",
      "Adam has converged at step 339.\n",
      "\n",
      "+++('deep', [4, 4], 6, 128)+++\n",
      "Step: 00320, Loss: 0.010209, Target Loss: 0.001134, Minimum Loss at: 216 with 0.0093990\n",
      "Adam has converged at step 328.\n",
      "\n",
      "+++('deep', [4, 4], 6, 256)+++\n",
      "Step: 00420, Loss: 0.011411, Target Loss: 0.002766, Minimum Loss at: 323 with 0.0101070\n",
      "Adam has converged at step 424.\n",
      "\n",
      "+++('deep', [4, 4], 8, 32)+++\n",
      "Step: 00500, Loss: 0.001743, Target Loss: 0.009971, Minimum Loss at: 405 with 0.0012430\n",
      "Adam has converged at step 506.\n",
      "\n",
      "+++('deep', [4, 4], 8, 64)+++\n",
      "Step: 00520, Loss: 0.001853, Target Loss: 0.008420, Minimum Loss at: 425 with 0.0012470\n",
      "Adam has converged at step 526.\n",
      "\n",
      "+++('deep', [4, 4], 8, 128)+++\n",
      "Step: 00380, Loss: 0.010252, Target Loss: 0.001246, Minimum Loss at: 279 with 0.0100420\n",
      "Adam has converged at step 381.\n",
      "\n",
      "+++('deep', [4, 4], 8, 256)+++\n",
      "Step: 00200, Loss: 0.011997, Target Loss: 0.002908, Minimum Loss at: 108 with 0.0108120\n",
      "Adam has converged at step 209.\n",
      "\n",
      "+++('deep', [2, 2], 4, 32)+++\n",
      "Step: 00640, Loss: 0.015846, Target Loss: 0.029383, Minimum Loss at: 545 with 0.0148170\n",
      "Adam has converged at step 646.\n",
      "\n",
      "+++('deep', [2, 2], 4, 64)+++\n",
      "Step: 00230, Loss: 0.027091, Target Loss: 0.029178, Minimum Loss at: 122 with 0.0229130\n",
      "Adam has converged at step 234.\n",
      "\n",
      "+++('deep', [2, 2], 4, 128)+++\n",
      "Step: 00240, Loss: 0.022769, Target Loss: 0.021694, Minimum Loss at: 136 with 0.0227500\n",
      "Adam has converged at step 246.\n",
      "\n",
      "+++('deep', [2, 2], 4, 256)+++\n",
      "Step: 00180, Loss: 0.065639, Target Loss: 0.073051, Minimum Loss at: 89 with 0.04456200\n",
      "Adam has converged at step 190.\n",
      "\n",
      "+++('deep', [2, 2], 6, 32)+++\n",
      "Step: 00460, Loss: 0.001958, Target Loss: 0.010742, Minimum Loss at: 369 with 0.0018160\n",
      "Adam has converged at step 470.\n",
      "\n",
      "+++('deep', [2, 2], 6, 64)+++\n",
      "Step: 00170, Loss: 0.009650, Target Loss: 0.018229, Minimum Loss at: 77 with 0.00377500\n",
      "Adam has converged at step 178.\n",
      "\n",
      "+++('deep', [2, 2], 6, 128)+++\n",
      "Step: 00340, Loss: 0.018106, Target Loss: 0.012057, Minimum Loss at: 242 with 0.0068430\n",
      "Adam has converged at step 343.\n",
      "\n",
      "+++('deep', [2, 2], 6, 256)+++\n",
      "Step: 00170, Loss: 0.032708, Target Loss: 0.031539, Minimum Loss at: 74 with 0.01408800\n",
      "Adam has converged at step 175.\n",
      "\n",
      "+++('deep', [2, 2], 8, 32)+++\n",
      "Step: 00470, Loss: 0.002074, Target Loss: 0.010067, Minimum Loss at: 372 with 0.0018350\n",
      "Adam has converged at step 473.\n",
      "\n",
      "+++('deep', [2, 2], 8, 64)+++\n",
      "Step: 00360, Loss: 0.003324, Target Loss: 0.011565, Minimum Loss at: 259 with 0.0017950\n",
      "Adam has converged at step 361.\n",
      "\n",
      "+++('deep', [2, 2], 8, 128)+++\n",
      "Step: 00340, Loss: 0.011342, Target Loss: 0.003549, Minimum Loss at: 247 with 0.0065710\n",
      "Adam has converged at step 348.\n",
      "\n",
      "+++('deep', [2, 2], 8, 256)+++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00290, Loss: 0.018259, Target Loss: 0.010847, Minimum Loss at: 198 with 0.0107470\n",
      "Adam has converged at step 299.\n",
      "\n",
      "+++('conv', [12, 12], 4, 32)+++\n",
      "Step: 01110, Loss: 0.008475, Target Loss: 0.021600, Minimum Loss at: 1016 with 0.005004\n",
      "Adam has converged at step 1117.\n",
      "\n",
      "+++('conv', [12, 12], 4, 64)+++\n",
      "Step: 01010, Loss: 0.017265, Target Loss: 0.034096, Minimum Loss at: 918 with 0.0085190\n",
      "Adam has converged at step 1019.\n",
      "\n",
      "+++('conv', [12, 12], 4, 128)+++\n",
      "Step: 00510, Loss: 0.064309, Target Loss: 0.091349, Minimum Loss at: 414 with 0.0346640\n",
      "Adam has converged at step 515.\n",
      "\n",
      "+++('conv', [12, 12], 4, 256)+++\n",
      "Step: 01480, Loss: 0.010886, Target Loss: 0.024963, Minimum Loss at: 1381 with 0.002350\n",
      "Adam has converged at step 1482.\n",
      "\n",
      "+++('conv', [12, 12], 6, 32)+++\n",
      "Step: 00690, Loss: 0.006357, Target Loss: 0.018846, Minimum Loss at: 595 with 0.0022100\n",
      "Adam has converged at step 697.\n",
      "\n",
      "+++('conv', [12, 12], 6, 64)+++\n",
      "Step: 00850, Loss: 0.001942, Target Loss: 0.012615, Minimum Loss at: 751 with 0.0015800\n",
      "Adam has converged at step 852.\n",
      "\n",
      "+++('conv', [12, 12], 6, 128)+++\n",
      "Step: 01070, Loss: 0.001404, Target Loss: 0.011874, Minimum Loss at: 970 with 0.0008700\n",
      "Adam has converged at step 1072.\n",
      "\n",
      "+++('conv', [12, 12], 6, 256)+++\n",
      "Step: 01350, Loss: 0.001557, Target Loss: 0.012114, Minimum Loss at: 1256 with 0.001031\n",
      "Adam has converged at step 1358.\n",
      "\n",
      "+++('conv', [12, 12], 8, 32)+++\n",
      "Step: 00390, Loss: 0.064170, Target Loss: 0.095586, Minimum Loss at: 295 with 0.0291990\n",
      "Adam has converged at step 397.\n",
      "\n",
      "+++('conv', [12, 12], 8, 64)+++\n",
      "Step: 00500, Loss: 0.023638, Target Loss: 0.040610, Minimum Loss at: 400 with 0.0105120\n",
      "Adam has converged at step 502.\n",
      "\n",
      "+++('conv', [12, 12], 8, 128)+++\n",
      "Step: 00330, Loss: 0.044945, Target Loss: 0.069980, Minimum Loss at: 237 with 0.0180290\n",
      "Adam has converged at step 338.\n",
      "\n",
      "+++('conv', [12, 12], 8, 256)+++\n",
      "Step: 00430, Loss: 0.043403, Target Loss: 0.067985, Minimum Loss at: 338 with 0.0361000\n",
      "Adam has converged at step 439.\n",
      "\n",
      "+++('conv', [10, 10], 4, 32)+++\n",
      "Step: 00840, Loss: 0.018084, Target Loss: 0.033160, Minimum Loss at: 745 with 0.0017360\n",
      "Adam has converged at step 846.\n",
      "\n",
      "+++('conv', [10, 10], 4, 64)+++\n",
      "Step: 01100, Loss: 0.004015, Target Loss: 0.015264, Minimum Loss at: 1005 with 0.003491\n",
      "Adam has converged at step 1106.\n",
      "\n",
      "+++('conv', [10, 10], 4, 128)+++\n",
      "Step: 01100, Loss: 0.008268, Target Loss: 0.020495, Minimum Loss at: 1009 with 0.002746\n",
      "Adam has converged at step 1110.\n",
      "\n",
      "+++('conv', [10, 10], 4, 256)+++\n",
      "Step: 00970, Loss: 0.014150, Target Loss: 0.027743, Minimum Loss at: 876 with 0.0111900\n",
      "Adam has converged at step 977.\n",
      "\n",
      "+++('conv', [10, 10], 6, 32)+++\n",
      "Step: 00570, Loss: 0.009142, Target Loss: 0.022512, Minimum Loss at: 472 with 0.0037080\n",
      "Adam has converged at step 573.\n",
      "\n",
      "+++('conv', [10, 10], 6, 64)+++\n",
      "Step: 00890, Loss: 0.001321, Target Loss: 0.011699, Minimum Loss at: 796 with 0.0007830\n",
      "Adam has converged at step 897.\n",
      "\n",
      "+++('conv', [10, 10], 6, 128)+++\n",
      "Step: 00600, Loss: 0.004404, Target Loss: 0.015913, Minimum Loss at: 507 with 0.0033570\n",
      "Adam has converged at step 608.\n",
      "\n",
      "+++('conv', [10, 10], 6, 256)+++\n",
      "Step: 00790, Loss: 0.001822, Target Loss: 0.013138, Minimum Loss at: 690 with 0.0014240\n",
      "Adam has converged at step 792.\n",
      "\n",
      "+++('conv', [10, 10], 8, 32)+++\n",
      "Step: 00300, Loss: 0.036553, Target Loss: 0.058150, Minimum Loss at: 201 with 0.0236490\n",
      "Adam has converged at step 302.\n",
      "\n",
      "+++('conv', [10, 10], 8, 64)+++\n",
      "Step: 00420, Loss: 0.014956, Target Loss: 0.029513, Minimum Loss at: 320 with 0.0083030\n",
      "Adam has converged at step 422.\n",
      "\n",
      "+++('conv', [10, 10], 8, 128)+++\n",
      "Step: 00540, Loss: 0.009664, Target Loss: 0.022968, Minimum Loss at: 440 with 0.0071130\n",
      "Adam has converged at step 542.\n",
      "\n",
      "+++('conv', [10, 10], 8, 256)+++\n",
      "Step: 00320, Loss: 0.122755, Target Loss: 0.173364, Minimum Loss at: 222 with 0.1082620\n",
      "Adam has converged at step 324.\n",
      "\n",
      "+++('conv', [8, 8], 4, 32)+++\n",
      "Step: 00930, Loss: 0.006240, Target Loss: 0.018118, Minimum Loss at: 837 with 0.0057770\n",
      "Adam has converged at step 938.\n",
      "\n",
      "+++('conv', [8, 8], 4, 64)+++\n",
      "Step: 00840, Loss: 0.007599, Target Loss: 0.019489, Minimum Loss at: 747 with 0.0066510\n",
      "Adam has converged at step 848.\n",
      "\n",
      "+++('conv', [8, 8], 4, 128)+++\n",
      "Step: 01030, Loss: 0.009906, Target Loss: 0.023332, Minimum Loss at: 934 with 0.0050490\n",
      "Adam has converged at step 1035.\n",
      "\n",
      "+++('conv', [8, 8], 4, 256)+++\n",
      "Step: 01470, Loss: 0.040180, Target Loss: 0.055941, Minimum Loss at: 1372 with 0.002349\n",
      "Adam has converged at step 1474.\n",
      "\n",
      "+++('conv', [8, 8], 6, 32)+++\n",
      "Step: 00870, Loss: 0.000712, Target Loss: 0.011072, Minimum Loss at: 779 with 0.0002100\n",
      "Adam has converged at step 880.\n",
      "\n",
      "+++('conv', [8, 8], 6, 64)+++\n",
      "Step: 00730, Loss: 0.000970, Target Loss: 0.010788, Minimum Loss at: 633 with 0.0003410\n",
      "Adam has converged at step 734.\n",
      "\n",
      "+++('conv', [8, 8], 6, 128)+++\n",
      "Step: 02080, Loss: 0.000161, Target Loss: 0.010454, Minimum Loss at: 1985 with 0.000145\n",
      "Adam has converged at step 2087.\n",
      "\n",
      "+++('conv', [8, 8], 6, 256)+++\n",
      "Step: 01740, Loss: 0.000612, Target Loss: 0.012000, Minimum Loss at: 1648 with 0.000522\n",
      "Adam has converged at step 1750.\n",
      "\n",
      "+++('conv', [8, 8], 8, 32)+++\n",
      "Step: 00470, Loss: 0.030405, Target Loss: 0.050253, Minimum Loss at: 374 with 0.0053410\n",
      "Adam has converged at step 475.\n",
      "\n",
      "+++('conv', [8, 8], 8, 64)+++\n",
      "Step: 00920, Loss: 0.008003, Target Loss: 0.020816, Minimum Loss at: 827 with 0.0015330\n",
      "Adam has converged at step 928.\n",
      "\n",
      "+++('conv', [8, 8], 8, 128)+++\n",
      "Step: 00750, Loss: 0.003031, Target Loss: 0.012970, Minimum Loss at: 659 with 0.0023910\n",
      "Adam has converged at step 760.\n",
      "\n",
      "+++('conv', [8, 8], 8, 256)+++\n",
      "Step: 00650, Loss: 0.030313, Target Loss: 0.057278, Minimum Loss at: 552 with 0.0020940\n",
      "Adam has converged at step 654.\n",
      "\n",
      "+++('conv', [6, 6], 4, 32)+++\n",
      "Step: 00790, Loss: 0.011059, Target Loss: 0.024085, Minimum Loss at: 693 with 0.0088380\n",
      "Adam has converged at step 794.\n",
      "\n",
      "+++('conv', [6, 6], 4, 64)+++\n",
      "Step: 00810, Loss: 0.008147, Target Loss: 0.020578, Minimum Loss at: 713 with 0.0078990\n",
      "Adam has converged at step 814.\n",
      "\n",
      "+++('conv', [6, 6], 4, 128)+++\n",
      "Step: 00900, Loss: 0.010296, Target Loss: 0.023599, Minimum Loss at: 808 with 0.0048030\n",
      "Adam has converged at step 909.\n",
      "\n",
      "+++('conv', [6, 6], 4, 256)+++\n",
      "Step: 01410, Loss: 0.009026, Target Loss: 0.021476, Minimum Loss at: 1316 with 0.006489\n",
      "Adam has converged at step 1417.\n",
      "\n",
      "+++('conv', [6, 6], 6, 32)+++\n",
      "Step: 00320, Loss: 0.007024, Target Loss: 0.022663, Minimum Loss at: 221 with 0.0048870\n",
      "Adam has converged at step 322.\n",
      "\n",
      "+++('conv', [6, 6], 6, 64)+++\n",
      "Step: 00390, Loss: 0.002678, Target Loss: 0.013607, Minimum Loss at: 293 with 0.0023450\n",
      "Adam has converged at step 394.\n",
      "\n",
      "+++('conv', [6, 6], 6, 128)+++\n",
      "Step: 00560, Loss: 0.003168, Target Loss: 0.014025, Minimum Loss at: 467 with 0.0021660\n",
      "Adam has converged at step 569.\n",
      "\n",
      "+++('conv', [6, 6], 6, 256)+++\n",
      "Step: 00780, Loss: 0.002270, Target Loss: 0.012721, Minimum Loss at: 681 with 0.0018890\n",
      "Adam has converged at step 782.\n",
      "\n",
      "+++('conv', [6, 6], 8, 32)+++\n",
      "Step: 00210, Loss: 0.011235, Target Loss: 0.025137, Minimum Loss at: 113 with 0.0109970\n",
      "Adam has converged at step 214.\n",
      "\n",
      "+++('conv', [6, 6], 8, 64)+++\n",
      "Step: 00440, Loss: 0.011330, Target Loss: 0.025524, Minimum Loss at: 346 with 0.0035280\n",
      "Adam has converged at step 447.\n",
      "\n",
      "+++('conv', [6, 6], 8, 128)+++\n",
      "Step: 00210, Loss: 0.040584, Target Loss: 0.064196, Minimum Loss at: 119 with 0.0252560\n",
      "Adam has converged at step 220.\n",
      "\n",
      "+++('conv', [6, 6], 8, 256)+++\n",
      "Step: 00600, Loss: 0.009610, Target Loss: 0.023045, Minimum Loss at: 500 with 0.0053000\n",
      "Adam has converged at step 601.\n",
      "\n",
      "+++('conv', [4, 4], 4, 32)+++\n",
      "Step: 00520, Loss: 0.014134, Target Loss: 0.028941, Minimum Loss at: 427 with 0.0114310\n",
      "Adam has converged at step 528.\n",
      "\n",
      "+++('conv', [4, 4], 4, 64)+++\n",
      "Step: 00520, Loss: 0.025666, Target Loss: 0.040255, Minimum Loss at: 422 with 0.0086720\n",
      "Adam has converged at step 523.\n",
      "\n",
      "+++('conv', [4, 4], 4, 128)+++\n",
      "Step: 01930, Loss: 0.006952, Target Loss: 0.018226, Minimum Loss at: 1822 with 0.004844\n",
      "Adam has converged at step 1939.\n",
      "\n",
      "+++('conv', [4, 4], 4, 256)+++\n",
      "Step: 00470, Loss: 0.014661, Target Loss: 0.031815, Minimum Loss at: 375 with 0.0134070\n",
      "Adam has converged at step 476.\n",
      "\n",
      "+++('conv', [4, 4], 6, 32)+++\n",
      "Step: 00500, Loss: 0.008761, Target Loss: 0.021543, Minimum Loss at: 402 with 0.0021400\n",
      "Adam has converged at step 503.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+++('conv', [4, 4], 6, 64)+++\n",
      "Step: 00280, Loss: 0.032859, Target Loss: 0.061589, Minimum Loss at: 180 with 0.0030660\n",
      "Adam has converged at step 281.\n",
      "\n",
      "+++('conv', [4, 4], 6, 128)+++\n",
      "Step: 00510, Loss: 0.005864, Target Loss: 0.018201, Minimum Loss at: 415 with 0.0015330\n",
      "Adam has converged at step 517.\n",
      "\n",
      "+++('conv', [4, 4], 6, 256)+++\n",
      "Step: 00550, Loss: 0.005062, Target Loss: 0.016319, Minimum Loss at: 449 with 0.0037100\n",
      "Adam has converged at step 552.\n",
      "\n",
      "+++('conv', [4, 4], 8, 32)+++\n",
      "Step: 00450, Loss: 0.009712, Target Loss: 0.023022, Minimum Loss at: 352 with 0.0054430\n",
      "Adam has converged at step 453.\n",
      "\n",
      "+++('conv', [4, 4], 8, 64)+++\n",
      "Step: 00740, Loss: 0.002409, Target Loss: 0.013386, Minimum Loss at: 644 with 0.0013630\n",
      "Adam has converged at step 745.\n",
      "\n",
      "+++('conv', [4, 4], 8, 128)+++\n",
      "Step: 00460, Loss: 0.004561, Target Loss: 0.015872, Minimum Loss at: 362 with 0.0037000\n",
      "Adam has converged at step 464.\n",
      "\n",
      "+++('conv', [4, 4], 8, 256)+++\n",
      "Step: 00550, Loss: 0.010302, Target Loss: 0.024643, Minimum Loss at: 453 with 0.0047290\n",
      "Adam has converged at step 555.\n",
      "\n",
      "+++('conv', [2, 2], 4, 32)+++\n",
      "Step: 00310, Loss: 0.043840, Target Loss: 0.067322, Minimum Loss at: 211 with 0.0359290\n",
      "Adam has converged at step 312.\n",
      "\n",
      "+++('conv', [2, 2], 4, 64)+++\n",
      "Step: 00520, Loss: 0.031959, Target Loss: 0.051847, Minimum Loss at: 424 with 0.0309450\n",
      "Adam has converged at step 525.\n",
      "\n",
      "+++('conv', [2, 2], 4, 128)+++\n",
      "Step: 00810, Loss: 0.032553, Target Loss: 0.050719, Minimum Loss at: 699 with 0.0290690\n",
      "Adam has converged at step 816.\n",
      "\n",
      "+++('conv', [2, 2], 4, 256)+++\n",
      "Step: 00330, Loss: 0.088779, Target Loss: 0.112510, Minimum Loss at: 231 with 0.0346170\n",
      "Adam has converged at step 332.\n",
      "\n",
      "+++('conv', [2, 2], 6, 32)+++\n",
      "Step: 00350, Loss: 0.004413, Target Loss: 0.015459, Minimum Loss at: 258 with 0.0028090\n",
      "Adam has converged at step 359.\n",
      "\n",
      "+++('conv', [2, 2], 6, 64)+++\n",
      "Step: 00360, Loss: 0.005567, Target Loss: 0.017284, Minimum Loss at: 269 with 0.0032420\n",
      "Adam has converged at step 370.\n",
      "\n",
      "+++('conv', [2, 2], 6, 128)+++\n",
      "Step: 00440, Loss: 0.004152, Target Loss: 0.015543, Minimum Loss at: 345 with 0.0020900\n",
      "Adam has converged at step 446.\n",
      "\n",
      "+++('conv', [2, 2], 6, 256)+++\n",
      "Step: 00790, Loss: 0.002359, Target Loss: 0.011268, Minimum Loss at: 699 with 0.0018010\n",
      "Adam has converged at step 800.\n",
      "\n",
      "+++('conv', [2, 2], 8, 32)+++\n",
      "Step: 00760, Loss: 0.000224, Target Loss: 0.010422, Minimum Loss at: 665 with 0.0002110\n",
      "Adam has converged at step 769.\n",
      "\n",
      "+++('conv', [2, 2], 8, 64)+++\n",
      "Step: 00810, Loss: 0.000189, Target Loss: 0.010316, Minimum Loss at: 714 with 0.0001390\n",
      "Adam has converged at step 815.\n",
      "\n",
      "+++('conv', [2, 2], 8, 128)+++\n",
      "Step: 00770, Loss: 0.002088, Target Loss: 0.014464, Minimum Loss at: 676 with 0.0006530\n",
      "Adam has converged at step 777.\n",
      "\n",
      "+++('conv', [2, 2], 8, 256)+++\n",
      "Step: 01190, Loss: 0.002714, Target Loss: 0.017141, Minimum Loss at: 1084 with 0.000487\n",
      "Adam has converged at step 1191.\n",
      "\n",
      "+++('deep', [12, 12], 4, 32)+++\n",
      "Step: 00260, Loss: 0.001370, Target Loss: 0.009722, Minimum Loss at: 160 with 0.0013010\n",
      "Adam has converged at step 261.\n",
      "\n",
      "+++('deep', [12, 12], 4, 64)+++\n",
      "Step: 00480, Loss: 0.001263, Target Loss: 0.010153, Minimum Loss at: 388 with 0.0012160\n",
      "Adam has converged at step 489.\n",
      "\n",
      "+++('deep', [12, 12], 4, 128)+++\n",
      "Step: 00220, Loss: 0.009897, Target Loss: 0.000440, Minimum Loss at: 124 with 0.0051350\n",
      "Adam has converged at step 225.\n",
      "\n",
      "+++('deep', [12, 12], 4, 256)+++\n",
      "Step: 00320, Loss: 0.010189, Target Loss: 0.000250, Minimum Loss at: 225 with 0.0101570\n",
      "Adam has converged at step 327.\n",
      "\n",
      "+++('deep', [12, 12], 6, 32)+++\n",
      "Step: 00350, Loss: 0.001083, Target Loss: 0.009009, Minimum Loss at: 255 with 0.0010570\n",
      "Adam has converged at step 356.\n",
      "\n",
      "+++('deep', [12, 12], 6, 64)+++\n",
      "Step: 00710, Loss: 0.001082, Target Loss: 0.009561, Minimum Loss at: 614 with 0.0008980\n",
      "Adam has converged at step 715.\n",
      "\n",
      "+++('deep', [12, 12], 6, 128)+++\n",
      "Step: 00200, Loss: 0.010047, Target Loss: 0.000241, Minimum Loss at: 100 with 0.0098280\n",
      "Adam has converged at step 205.\n",
      "\n",
      "+++('deep', [12, 12], 6, 256)+++\n",
      "Step: 00330, Loss: 0.010251, Target Loss: 0.000650, Minimum Loss at: 226 with 0.0101810\n",
      "Adam has converged at step 333.\n",
      "\n",
      "+++('deep', [12, 12], 8, 32)+++\n",
      "Step: 00730, Loss: 0.000885, Target Loss: 0.009729, Minimum Loss at: 631 with 0.0008230\n",
      "Adam has converged at step 732.\n",
      "\n",
      "+++('deep', [12, 12], 8, 64)+++\n",
      "Step: 00440, Loss: 0.001158, Target Loss: 0.009863, Minimum Loss at: 345 with 0.0009930\n",
      "Adam has converged at step 446.\n",
      "\n",
      "+++('deep', [12, 12], 8, 128)+++\n",
      "Step: 00120, Loss: 0.009945, Target Loss: 0.000453, Minimum Loss at: 25 with 0.00322900\n",
      "Adam has converged at step 126.\n",
      "\n",
      "+++('deep', [12, 12], 8, 256)+++\n",
      "Step: 00350, Loss: 0.010572, Target Loss: 0.000337, Minimum Loss at: 259 with 0.0100370\n",
      "Adam has converged at step 360.\n",
      "\n",
      "+++('deep', [10, 10], 4, 32)+++\n",
      "Step: 00650, Loss: 0.001238, Target Loss: 0.009006, Minimum Loss at: 475 with 0.0011140\n",
      "Adam has converged at step 651.\n",
      "\n",
      "+++('deep', [10, 10], 4, 64)+++\n",
      "Step: 00330, Loss: 0.001376, Target Loss: 0.007964, Minimum Loss at: 232 with 0.0013670\n",
      "Adam has converged at step 333.\n",
      "\n",
      "+++('deep', [10, 10], 4, 128)+++\n",
      "Step: 00160, Loss: 0.009063, Target Loss: 0.001563, Minimum Loss at: 69 with 0.00818100\n",
      "Adam has converged at step 170.\n",
      "\n",
      "+++('deep', [10, 10], 4, 256)+++\n",
      "Step: 00200, Loss: 0.010129, Target Loss: 0.000491, Minimum Loss at: 102 with 0.0099740\n",
      "Adam has converged at step 203.\n",
      "\n",
      "+++('deep', [10, 10], 6, 32)+++\n",
      "Step: 00240, Loss: 0.001297, Target Loss: 0.008087, Minimum Loss at: 141 with 0.0012560\n",
      "Adam has converged at step 242.\n",
      "\n",
      "+++('deep', [10, 10], 6, 64)+++\n",
      "Step: 00500, Loss: 0.001091, Target Loss: 0.009185, Minimum Loss at: 403 with 0.0010010\n",
      "Adam has converged at step 505.\n",
      "\n",
      "+++('deep', [10, 10], 6, 128)+++\n",
      "Step: 00140, Loss: 0.011389, Target Loss: 0.001666, Minimum Loss at: 49 with 0.00767200\n",
      "Adam has converged at step 150.\n",
      "\n",
      "+++('deep', [10, 10], 6, 256)+++\n",
      "Step: 00450, Loss: 0.010217, Target Loss: 0.000519, Minimum Loss at: 334 with 0.0100640\n",
      "Adam has converged at step 454.\n",
      "\n",
      "+++('deep', [10, 10], 8, 32)+++\n",
      "Step: 00260, Loss: 0.001436, Target Loss: 0.008335, Minimum Loss at: 135 with 0.0013560\n",
      "Adam has converged at step 265.\n",
      "\n",
      "+++('deep', [10, 10], 8, 64)+++\n",
      "Step: 00440, Loss: 0.009948, Target Loss: 0.001841, Minimum Loss at: 343 with 0.0011080\n",
      "Adam has converged at step 444.\n",
      "\n",
      "+++('deep', [10, 10], 8, 128)+++\n",
      "Step: 00360, Loss: 0.010680, Target Loss: 0.000595, Minimum Loss at: 263 with 0.0089930\n",
      "Adam has converged at step 364.\n",
      "\n",
      "+++('deep', [10, 10], 8, 256)+++\n",
      "Step: 00830, Loss: 0.009999, Target Loss: 0.000513, Minimum Loss at: 733 with 0.0099230\n",
      "Adam has converged at step 835.\n",
      "\n",
      "+++('deep', [8, 8], 4, 32)+++\n",
      "Step: 00320, Loss: 0.001411, Target Loss: 0.009778, Minimum Loss at: 225 with 0.0013800\n",
      "Adam has converged at step 326.\n",
      "\n",
      "+++('deep', [8, 8], 4, 64)+++\n",
      "Step: 00180, Loss: 0.001753, Target Loss: 0.008781, Minimum Loss at: 83 with 0.00165700\n",
      "Adam has converged at step 184.\n",
      "\n",
      "+++('deep', [8, 8], 4, 128)+++\n",
      "Step: 00200, Loss: 0.010316, Target Loss: 0.001103, Minimum Loss at: 76 with 0.01018700\n",
      "Adam has converged at step 202.\n",
      "\n",
      "+++('deep', [8, 8], 4, 256)+++\n",
      "Step: 00360, Loss: 0.010349, Target Loss: 0.000918, Minimum Loss at: 261 with 0.0101400\n",
      "Adam has converged at step 370.\n",
      "\n",
      "+++('deep', [8, 8], 6, 32)+++\n",
      "Step: 00580, Loss: 0.001475, Target Loss: 0.008793, Minimum Loss at: 457 with 0.0012960\n",
      "Adam has converged at step 587.\n",
      "\n",
      "+++('deep', [8, 8], 6, 64)+++\n",
      "Step: 00290, Loss: 0.001335, Target Loss: 0.008558, Minimum Loss at: 198 with 0.0012520\n",
      "Adam has converged at step 299.\n",
      "\n",
      "+++('deep', [8, 8], 6, 128)+++\n",
      "Step: 00120, Loss: 0.010080, Target Loss: 0.000419, Minimum Loss at: 25 with 0.00759000\n",
      "Adam has converged at step 126.\n",
      "\n",
      "+++('deep', [8, 8], 6, 256)+++\n",
      "Step: 00290, Loss: 0.010386, Target Loss: 0.000847, Minimum Loss at: 127 with 0.0101770\n",
      "Adam has converged at step 291.\n",
      "\n",
      "+++('deep', [8, 8], 8, 32)+++\n",
      "Step: 00640, Loss: 0.001261, Target Loss: 0.009093, Minimum Loss at: 542 with 0.0010290\n",
      "Adam has converged at step 643.\n",
      "\n",
      "+++('deep', [8, 8], 8, 64)+++\n",
      "Step: 00870, Loss: 0.001100, Target Loss: 0.009155, Minimum Loss at: 775 with 0.0009040\n",
      "Adam has converged at step 876.\n",
      "\n",
      "+++('deep', [8, 8], 8, 128)+++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00520, Loss: 0.009939, Target Loss: 0.000494, Minimum Loss at: 428 with 0.0095270\n",
      "Adam has converged at step 529.\n",
      "\n",
      "+++('deep', [8, 8], 8, 256)+++\n",
      "Step: 00320, Loss: 0.010227, Target Loss: 0.000321, Minimum Loss at: 218 with 0.0100790\n",
      "Adam has converged at step 330.\n",
      "\n",
      "+++('deep', [6, 6], 4, 32)+++\n",
      "Step: 00350, Loss: 0.001879, Target Loss: 0.009852, Minimum Loss at: 255 with 0.0017300\n",
      "Adam has converged at step 356.\n",
      "\n",
      "+++('deep', [6, 6], 4, 64)+++\n",
      "Step: 00210, Loss: 0.008897, Target Loss: 0.003340, Minimum Loss at: 110 with 0.0024260\n",
      "Adam has converged at step 211.\n",
      "\n",
      "+++('deep', [6, 6], 4, 128)+++\n",
      "Step: 00180, Loss: 0.010781, Target Loss: 0.001556, Minimum Loss at: 84 with 0.01040800\n",
      "Adam has converged at step 185.\n",
      "\n",
      "+++('deep', [6, 6], 4, 256)+++\n",
      "Step: 00130, Loss: 0.018257, Target Loss: 0.010074, Minimum Loss at: 35 with 0.01227300\n",
      "Adam has converged at step 136.\n",
      "\n",
      "+++('deep', [6, 6], 6, 32)+++\n",
      "Step: 00320, Loss: 0.001693, Target Loss: 0.009504, Minimum Loss at: 222 with 0.0014620\n",
      "Adam has converged at step 324.\n",
      "\n",
      "+++('deep', [6, 6], 6, 64)+++\n",
      "Step: 00670, Loss: 0.001269, Target Loss: 0.009728, Minimum Loss at: 576 with 0.0011630\n",
      "Adam has converged at step 677.\n",
      "\n",
      "+++('deep', [6, 6], 6, 128)+++\n",
      "Step: 00190, Loss: 0.010349, Target Loss: 0.000822, Minimum Loss at: 81 with 0.01011500\n",
      "Adam has converged at step 193.\n",
      "\n",
      "+++('deep', [6, 6], 6, 256)+++\n",
      "Step: 00220, Loss: 0.010812, Target Loss: 0.001248, Minimum Loss at: 129 with 0.0101810\n",
      "Adam has converged at step 230.\n",
      "\n",
      "+++('deep', [6, 6], 8, 32)+++\n",
      "Step: 00820, Loss: 0.001199, Target Loss: 0.009072, Minimum Loss at: 720 with 0.0011850\n",
      "Adam has converged at step 821.\n",
      "\n",
      "+++('deep', [6, 6], 8, 64)+++\n",
      "Step: 00340, Loss: 0.001522, Target Loss: 0.009221, Minimum Loss at: 246 with 0.0011780\n",
      "Adam has converged at step 347.\n",
      "\n",
      "+++('deep', [6, 6], 8, 128)+++\n",
      "Step: 00260, Loss: 0.009980, Target Loss: 0.000658, Minimum Loss at: 165 with 0.0085380\n",
      "Adam has converged at step 266.\n",
      "\n",
      "+++('deep', [6, 6], 8, 256)+++\n",
      "Step: 00220, Loss: 0.010265, Target Loss: 0.000167, Minimum Loss at: 129 with 0.0101720\n",
      "Adam has converged at step 230.\n",
      "\n",
      "+++('deep', [4, 4], 4, 32)+++\n",
      "Step: 00600, Loss: 0.011327, Target Loss: 0.022401, Minimum Loss at: 505 with 0.0052380\n",
      "Adam has converged at step 606.\n",
      "\n",
      "+++('deep', [4, 4], 4, 64)+++\n",
      "Step: 00580, Loss: 0.006798, Target Loss: 0.020730, Minimum Loss at: 483 with 0.0052790\n",
      "Adam has converged at step 584.\n",
      "\n",
      "+++('deep', [4, 4], 4, 128)+++\n",
      "Step: 00420, Loss: 0.011261, Target Loss: 0.009658, Minimum Loss at: 324 with 0.0081770\n",
      "Adam has converged at step 426.\n",
      "\n",
      "+++('deep', [4, 4], 4, 256)+++\n",
      "Step: 00210, Loss: 0.026292, Target Loss: 0.022031, Minimum Loss at: 115 with 0.0178210\n",
      "Adam has converged at step 216.\n",
      "\n",
      "+++('deep', [4, 4], 6, 32)+++\n",
      "Step: 00200, Loss: 0.001732, Target Loss: 0.009676, Minimum Loss at: 100 with 0.0017060\n",
      "Adam has converged at step 201.\n",
      "\n",
      "+++('deep', [4, 4], 6, 64)+++\n",
      "Step: 00240, Loss: 0.001747, Target Loss: 0.009483, Minimum Loss at: 149 with 0.0016570\n",
      "Adam has converged at step 250.\n",
      "\n",
      "+++('deep', [4, 4], 6, 128)+++\n",
      "Step: 00530, Loss: 0.010126, Target Loss: 0.000892, Minimum Loss at: 433 with 0.0042100\n",
      "Adam has converged at step 535.\n",
      "\n",
      "+++('deep', [4, 4], 6, 256)+++\n",
      "Step: 00360, Loss: 0.014831, Target Loss: 0.005564, Minimum Loss at: 261 with 0.0105810\n",
      "Adam has converged at step 362.\n",
      "\n",
      "+++('deep', [4, 4], 8, 32)+++\n",
      "Step: 00390, Loss: 0.001566, Target Loss: 0.009205, Minimum Loss at: 291 with 0.0013110\n",
      "Adam has converged at step 393.\n",
      "\n",
      "+++('deep', [4, 4], 8, 64)+++\n",
      "Step: 00470, Loss: 0.001402, Target Loss: 0.008623, Minimum Loss at: 373 with 0.0013510\n",
      "Adam has converged at step 474.\n",
      "\n",
      "+++('deep', [4, 4], 8, 128)+++\n",
      "Step: 00180, Loss: 0.010187, Target Loss: 0.000947, Minimum Loss at: 88 with 0.00518000\n",
      "Adam has converged at step 189.\n",
      "\n",
      "+++('deep', [4, 4], 8, 256)+++\n",
      "Step: 00450, Loss: 0.010301, Target Loss: 0.001110, Minimum Loss at: 353 with 0.0100810\n",
      "Adam has converged at step 454.\n",
      "\n",
      "+++('deep', [2, 2], 4, 32)+++\n",
      "Step: 00640, Loss: 0.015697, Target Loss: 0.029145, Minimum Loss at: 484 with 0.0149870\n",
      "Adam has converged at step 644.\n",
      "\n",
      "+++('deep', [2, 2], 4, 64)+++\n",
      "Step: 01200, Loss: 0.040565, Target Loss: 0.061934, Minimum Loss at: 1109 with 0.013754\n",
      "Adam has converged at step 1210.\n",
      "\n",
      "+++('deep', [2, 2], 4, 128)+++\n",
      "Step: 00290, Loss: 0.022924, Target Loss: 0.021484, Minimum Loss at: 187 with 0.0226800\n",
      "Adam has converged at step 298.\n",
      "\n",
      "+++('deep', [2, 2], 4, 256)+++\n",
      "Step: 00190, Loss: 0.084735, Target Loss: 0.101978, Minimum Loss at: 99 with 0.04100700\n",
      "Adam has converged at step 200.\n",
      "\n",
      "+++('deep', [2, 2], 6, 32)+++\n",
      "Step: 00320, Loss: 0.006473, Target Loss: 0.015906, Minimum Loss at: 225 with 0.0027540\n",
      "Adam has converged at step 326.\n",
      "\n",
      "+++('deep', [2, 2], 6, 64)+++\n",
      "Step: 00490, Loss: 0.004154, Target Loss: 0.012884, Minimum Loss at: 397 with 0.0025960\n",
      "Adam has converged at step 498.\n",
      "\n",
      "+++('deep', [2, 2], 6, 128)+++\n",
      "Step: 00230, Loss: 0.012915, Target Loss: 0.007161, Minimum Loss at: 137 with 0.0109410\n",
      "Adam has converged at step 238.\n",
      "\n",
      "+++('deep', [2, 2], 6, 256)+++\n",
      "Step: 00550, Loss: 0.010482, Target Loss: 0.001654, Minimum Loss at: 445 with 0.0101600\n",
      "Adam has converged at step 554.\n",
      "\n",
      "+++('deep', [2, 2], 8, 32)+++\n",
      "Step: 00500, Loss: 0.001991, Target Loss: 0.009998, Minimum Loss at: 401 with 0.0016280\n",
      "Adam has converged at step 502.\n",
      "\n",
      "+++('deep', [2, 2], 8, 64)+++\n",
      "Step: 00240, Loss: 0.005196, Target Loss: 0.013408, Minimum Loss at: 146 with 0.0021080\n",
      "Adam has converged at step 247.\n",
      "\n",
      "+++('deep', [2, 2], 8, 128)+++\n",
      "Step: 00390, Loss: 0.010236, Target Loss: 0.001707, Minimum Loss at: 296 with 0.0079940\n",
      "Adam has converged at step 397.\n",
      "\n",
      "+++('deep', [2, 2], 8, 256)+++\n",
      "Step: 00310, Loss: 0.016432, Target Loss: 0.007067, Minimum Loss at: 217 with 0.0117370\n",
      "Adam has converged at step 318.\n",
      "\n",
      "+++('conv', [12, 12], 4, 32)+++\n",
      "Step: 00740, Loss: 0.011665, Target Loss: 0.024881, Minimum Loss at: 641 with 0.0080570\n",
      "Adam has converged at step 742.\n",
      "\n",
      "+++('conv', [12, 12], 4, 64)+++\n",
      "Step: 01030, Loss: 0.010651, Target Loss: 0.024938, Minimum Loss at: 938 with 0.0068870\n",
      "Adam has converged at step 1039.\n",
      "\n",
      "+++('conv', [12, 12], 4, 128)+++\n",
      "Step: 01250, Loss: 0.002315, Target Loss: 0.013217, Minimum Loss at: 1158 with 0.001797\n",
      "Adam has converged at step 1259.\n",
      "\n",
      "+++('conv', [12, 12], 4, 256)+++\n",
      "Step: 01520, Loss: 0.043824, Target Loss: 0.060687, Minimum Loss at: 1422 with 0.002559\n",
      "Adam has converged at step 1523.\n",
      "\n",
      "+++('conv', [12, 12], 6, 32)+++\n",
      "Step: 00700, Loss: 0.002651, Target Loss: 0.013390, Minimum Loss at: 604 with 0.0020120\n",
      "Adam has converged at step 705.\n",
      "\n",
      "+++('conv', [12, 12], 6, 64)+++\n",
      "Step: 00670, Loss: 0.008982, Target Loss: 0.021695, Minimum Loss at: 571 with 0.0015200\n",
      "Adam has converged at step 673.\n",
      "\n",
      "+++('conv', [12, 12], 6, 128)+++\n",
      "Step: 00910, Loss: 0.025216, Target Loss: 0.052639, Minimum Loss at: 813 with 0.0009670\n",
      "Adam has converged at step 914.\n",
      "\n",
      "+++('conv', [12, 12], 6, 256)+++\n",
      "Step: 01080, Loss: 0.001149, Target Loss: 0.011513, Minimum Loss at: 988 with 0.0008760\n",
      "Adam has converged at step 1089.\n",
      "\n",
      "+++('conv', [12, 12], 8, 32)+++\n",
      "Step: 00280, Loss: 0.055536, Target Loss: 0.084522, Minimum Loss at: 188 with 0.0396290\n",
      "Adam has converged at step 289.\n",
      "\n",
      "+++('conv', [12, 12], 8, 64)+++\n",
      "Step: 00530, Loss: 0.005428, Target Loss: 0.016799, Minimum Loss at: 431 with 0.0034230\n",
      "Adam has converged at step 533.\n",
      "\n",
      "+++('conv', [12, 12], 8, 128)+++\n",
      "Step: 00560, Loss: 0.016251, Target Loss: 0.027984, Minimum Loss at: 459 with 0.0088210\n",
      "Adam has converged at step 561.\n",
      "\n",
      "+++('conv', [12, 12], 8, 256)+++\n",
      "Step: 00450, Loss: 0.035267, Target Loss: 0.057537, Minimum Loss at: 352 with 0.0283860\n",
      "Adam has converged at step 453.\n",
      "\n",
      "+++('conv', [10, 10], 4, 32)+++\n",
      "Step: 00730, Loss: 0.009062, Target Loss: 0.019360, Minimum Loss at: 635 with 0.0053240\n",
      "Adam has converged at step 736.\n",
      "\n",
      "+++('conv', [10, 10], 4, 64)+++\n",
      "Step: 00970, Loss: 0.002792, Target Loss: 0.013341, Minimum Loss at: 876 with 0.0016510\n",
      "Adam has converged at step 977.\n",
      "\n",
      "+++('conv', [10, 10], 4, 128)+++\n",
      "Step: 01100, Loss: 0.003950, Target Loss: 0.015070, Minimum Loss at: 996 with 0.0037910\n",
      "Adam has converged at step 1101.\n",
      "\n",
      "+++('conv', [10, 10], 4, 256)+++\n",
      "Step: 01280, Loss: 0.004650, Target Loss: 0.016039, Minimum Loss at: 1183 with 0.002850\n",
      "Adam has converged at step 1284.\n",
      "\n",
      "+++('conv', [10, 10], 6, 32)+++\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 00450, Loss: 0.008728, Target Loss: 0.021768, Minimum Loss at: 354 with 0.0047200\n",
      "Adam has converged at step 455.\n",
      "\n",
      "+++('conv', [10, 10], 6, 64)+++\n",
      "Step: 00380, Loss: 0.019937, Target Loss: 0.035495, Minimum Loss at: 289 with 0.0072980\n",
      "Adam has converged at step 390.\n",
      "\n",
      "+++('conv', [10, 10], 6, 128)+++\n",
      "Step: 00700, Loss: 0.004489, Target Loss: 0.016025, Minimum Loss at: 607 with 0.0023860\n",
      "Adam has converged at step 709.\n",
      "\n",
      "+++('conv', [10, 10], 6, 256)+++\n",
      "Step: 01120, Loss: 0.024254, Target Loss: 0.041546, Minimum Loss at: 1029 with 0.001283\n",
      "Adam has converged at step 1130.\n",
      "\n",
      "+++('conv', [10, 10], 8, 32)+++\n",
      "Step: 00510, Loss: 0.033450, Target Loss: 0.054275, Minimum Loss at: 415 with 0.0189630\n",
      "Adam has converged at step 516.\n",
      "\n",
      "+++('conv', [10, 10], 8, 64)+++\n",
      "Step: 00490, Loss: 0.029639, Target Loss: 0.049598, Minimum Loss at: 393 with 0.0121270\n",
      "Adam has converged at step 494.\n",
      "\n",
      "+++('conv', [10, 10], 8, 128)+++\n",
      "Step: 00370, Loss: 0.019182, Target Loss: 0.035283, Minimum Loss at: 266 with 0.0170420\n",
      "Adam has converged at step 373.\n",
      "\n",
      "+++('conv', [10, 10], 8, 256)+++\n",
      "Step: 00450, Loss: 0.082288, Target Loss: 0.119779, Minimum Loss at: 356 with 0.0441650\n",
      "Adam has converged at step 457.\n",
      "\n",
      "+++('conv', [8, 8], 4, 32)+++\n",
      "Step: 01230, Loss: 0.005657, Target Loss: 0.016871, Minimum Loss at: 1134 with 0.005036\n",
      "Adam has converged at step 1235.\n",
      "\n",
      "+++('conv', [8, 8], 4, 64)+++\n",
      "Step: 01120, Loss: 0.003641, Target Loss: 0.014875, Minimum Loss at: 1021 with 0.002821\n",
      "Adam has converged at step 1127.\n",
      "\n",
      "+++('conv', [8, 8], 4, 128)+++\n",
      "Step: 00830, Loss: 0.003694, Target Loss: 0.013644, Minimum Loss at: 733 with 0.0028510\n",
      "Adam has converged at step 834.\n",
      "\n",
      "+++('conv', [8, 8], 4, 256)+++\n",
      "Step: 00980, Loss: 0.019256, Target Loss: 0.033365, Minimum Loss at: 887 with 0.0081820\n",
      "Adam has converged at step 988.\n",
      "\n",
      "+++('conv', [8, 8], 6, 32)+++\n",
      "Step: 00390, Loss: 0.000741, Target Loss: 0.010116, Minimum Loss at: 293 with 0.0005500\n",
      "Adam has converged at step 394.\n",
      "\n",
      "+++('conv', [8, 8], 6, 64)+++\n",
      "Step: 01650, Loss: 0.000478, Target Loss: 0.009867, Minimum Loss at: 1548 with 0.000135\n",
      "Adam has converged at step 1654.\n",
      "\n",
      "+++('conv', [8, 8], 6, 128)+++\n",
      "Step: 00710, Loss: 0.000485, Target Loss: 0.010549, Minimum Loss at: 604 with 0.0002980\n",
      "Adam has converged at step 711.\n",
      "\n",
      "+++('conv', [8, 8], 6, 256)+++\n",
      "Step: 02250, Loss: 0.000146, Target Loss: 0.010186, Minimum Loss at: 2158 with 0.000135\n",
      "Adam has converged at step 2259.\n",
      "\n",
      "+++('conv', [8, 8], 8, 32)+++\n",
      "Step: 00430, Loss: 0.017194, Target Loss: 0.031618, Minimum Loss at: 332 with 0.0090700\n",
      "Adam has converged at step 433.\n",
      "\n",
      "+++('conv', [8, 8], 8, 64)+++\n",
      "Step: 00560, Loss: 0.004567, Target Loss: 0.016087, Minimum Loss at: 464 with 0.0038570\n",
      "Adam has converged at step 565.\n",
      "\n",
      "+++('conv', [8, 8], 8, 128)+++\n",
      "Step: 00300, Loss: 0.024656, Target Loss: 0.042842, Minimum Loss at: 205 with 0.0187030\n",
      "Adam has converged at step 307.\n",
      "\n",
      "+++('conv', [8, 8], 8, 256)+++\n",
      "Step: 00520, Loss: 0.007297, Target Loss: 0.020011, Minimum Loss at: 422 with 0.0048850\n",
      "Adam has converged at step 523.\n",
      "\n",
      "+++('conv', [6, 6], 4, 32)+++\n",
      "Step: 00850, Loss: 0.011552, Target Loss: 0.026880, Minimum Loss at: 752 with 0.0105440\n",
      "Adam has converged at step 853.\n",
      "\n",
      "+++('conv', [6, 6], 4, 64)+++\n",
      "Step: 00700, Loss: 0.018474, Target Loss: 0.032973, Minimum Loss at: 609 with 0.0098340\n",
      "Adam has converged at step 710.\n",
      "\n",
      "+++('conv', [6, 6], 4, 128)+++\n",
      "Step: 00760, Loss: 0.013800, Target Loss: 0.029827, Minimum Loss at: 662 with 0.0093120\n",
      "Adam has converged at step 763.\n",
      "\n",
      "+++('conv', [6, 6], 4, 256)+++\n",
      "Step: 01180, Loss: 0.012254, Target Loss: 0.025882, Minimum Loss at: 1084 with 0.011187\n",
      "Adam has converged at step 1185.\n",
      "\n",
      "+++('conv', [6, 6], 6, 32)+++\n",
      "Step: 00430, Loss: 0.004998, Target Loss: 0.015695, Minimum Loss at: 330 with 0.0027820\n",
      "Adam has converged at step 431.\n",
      "\n",
      "+++('conv', [6, 6], 6, 64)+++\n",
      "Step: 00550, Loss: 0.014587, Target Loss: 0.028478, Minimum Loss at: 459 with 0.0018140\n",
      "Adam has converged at step 560.\n",
      "\n",
      "+++('conv', [6, 6], 6, 128)+++\n",
      "Step: 00530, Loss: 0.009395, Target Loss: 0.019388, Minimum Loss at: 438 with 0.0019890\n",
      "Adam has converged at step 539.\n",
      "\n",
      "+++('conv', [6, 6], 6, 256)+++\n",
      "Step: 01420, Loss: 0.001187, Target Loss: 0.011893, Minimum Loss at: 1325 with 0.001013\n",
      "Adam has converged at step 1428.\n",
      "\n",
      "+++('conv', [6, 6], 8, 32)+++\n",
      "Step: 00580, Loss: 0.005028, Target Loss: 0.016594, Minimum Loss at: 482 with 0.0026810\n",
      "Adam has converged at step 584.\n",
      "\n",
      "+++('conv', [6, 6], 8, 64)+++\n",
      "Step: 00510, Loss: 0.003928, Target Loss: 0.015120, Minimum Loss at: 418 with 0.0035160\n",
      "Adam has converged at step 519.\n",
      "\n",
      "+++('conv', [6, 6], 8, 128)+++\n",
      "Step: 00650, Loss: 0.002461, Target Loss: 0.013205, Minimum Loss at: 557 with 0.0016550\n",
      "Adam has converged at step 658.\n",
      "\n",
      "+++('conv', [6, 6], 8, 256)+++\n",
      "Step: 00530, Loss: 0.005479, Target Loss: 0.017573, Minimum Loss at: 438 with 0.0049810\n",
      "Adam has converged at step 540.\n",
      "\n",
      "+++('conv', [4, 4], 4, 32)+++\n",
      "Step: 00350, Loss: 0.021427, Target Loss: 0.038741, Minimum Loss at: 252 with 0.0212580\n",
      "Adam has converged at step 353.\n",
      "\n",
      "+++('conv', [4, 4], 4, 64)+++\n",
      "Step: 00690, Loss: 0.013361, Target Loss: 0.028260, Minimum Loss at: 598 with 0.0107200\n",
      "Adam has converged at step 699.\n",
      "\n",
      "+++('conv', [4, 4], 4, 128)+++\n",
      "Step: 00870, Loss: 0.016031, Target Loss: 0.032251, Minimum Loss at: 771 with 0.0130410\n",
      "Adam has converged at step 872.\n",
      "\n",
      "+++('conv', [4, 4], 4, 256)+++\n",
      "Step: 00880, Loss: 0.011537, Target Loss: 0.025699, Minimum Loss at: 784 with 0.0072990\n",
      "Adam has converged at step 885.\n",
      "\n",
      "+++('conv', [4, 4], 6, 32)+++\n",
      "Step: 00280, Loss: 0.003322, Target Loss: 0.014023, Minimum Loss at: 188 with 0.0027880\n",
      "Adam has converged at step 289.\n",
      "\n",
      "+++('conv', [4, 4], 6, 64)+++\n",
      "Step: 00470, Loss: 0.001875, Target Loss: 0.012610, Minimum Loss at: 376 with 0.0017370\n",
      "Adam has converged at step 477.\n",
      "\n",
      "+++('conv', [4, 4], 6, 128)+++\n",
      "Step: 00350, Loss: 0.002534, Target Loss: 0.013097, Minimum Loss at: 256 with 0.0025010\n",
      "Adam has converged at step 357.\n",
      "\n",
      "+++('conv', [4, 4], 6, 256)+++\n",
      "Step: 00740, Loss: 0.004128, Target Loss: 0.016191, Minimum Loss at: 643 with 0.0034040\n",
      "Adam has converged at step 744.\n",
      "\n",
      "+++('conv', [4, 4], 8, 32)+++\n",
      "Step: 00270, Loss: 0.012140, Target Loss: 0.026362, Minimum Loss at: 179 with 0.0103670\n",
      "Adam has converged at step 280.\n",
      "\n",
      "+++('conv', [4, 4], 8, 64)+++\n",
      "Step: 00310, Loss: 0.007694, Target Loss: 0.020365, Minimum Loss at: 216 with 0.0049400\n",
      "Adam has converged at step 317.\n",
      "\n",
      "+++('conv', [4, 4], 8, 128)+++\n",
      "Step: 00300, Loss: 0.009669, Target Loss: 0.022031, Minimum Loss at: 198 with 0.0055560\n",
      "Adam has converged at step 301.\n",
      "\n",
      "+++('conv', [4, 4], 8, 256)+++\n",
      "Step: 00440, Loss: 0.011575, Target Loss: 0.025446, Minimum Loss at: 343 with 0.0075720\n",
      "Adam has converged at step 444.\n",
      "\n",
      "+++('conv', [2, 2], 4, 32)+++\n",
      "Step: 01250, Loss: 0.027798, Target Loss: 0.047457, Minimum Loss at: 1079 with 0.027871\n",
      "Adam has converged at step 1251.\n"
     ]
    }
   ],
   "source": [
    " for parameter_combination in parameter_combinations:\n",
    "        print(\"+++\" + str(parameter_combination) + \"+++\")\n",
    "        model = create_model_from_parameter_combination(parameter_combination, gridsearch_configuration.image_shape)\n",
    "        fitter(model, noisy_image, target_image)\n",
    "        result = fitter.get_result()\n",
    "        save_gridsearch_result(result, gridsearch_configuration.result_path)\n",
    "        print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
